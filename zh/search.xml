<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Numba: 通过python快速学习cuda编程</title>
    <url>/zh/2020/06/10/zh/numba_cuda/</url>
    <content><![CDATA[<p>复杂的编译环境配置，指针操作和debug过程，CUDA编程对于初学者来说总是望而生畏。本文旨在通过使用python的numba库，快速学习和了解CUDA多线程高并发的编程思路。</p>
<span id="more"></span>
<h2 id="环境配置">环境配置</h2>
<p>为了简化环境配置，本文中的编程环境将全部由conda配置，并在conda的虚拟环境中测试。所涉及的依赖库分别是<code>cudatoolkit</code>,
<code>numba</code>,
<code>numpy</code>。相关环境可以通过以下语令进行配置。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n numba-cuda python=3.7</span><br><span class="line">conda activate numba-cuda</span><br><span class="line">conda install cudatoolkit numba numpy</span><br></pre></td></tr></table></figure>
<p>当安装完成后，可以通过<code>nvidia-smi</code>去检查gpu状态，如下表所示。通过该表可以看到运行在每个gpu上的程序以及它们显存的使用占用，也可以通过memory-usage检查每个显卡总体显存占用。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |</span><br><span class="line">| 27%   36C    P8   112W / 250W |   6338MiB / 11175MiB |     38%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0     32597      G   /home/yang/anaconda3/envs/ssds/bin/python   6338MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>并且也可以通过<code>python -c "from numba import cuda; print(cuda.gpus)"</code>检查是否可以成功在numba库中访问到gpu设备。当其返回为<code>&lt;Managed Device 0&gt;...</code>时则证明可在python环境下成功访问显卡。</p>
<p>当主机没有gpu设备时，依然可以通过numba提供的gpu模拟器去运行python的cuda代码，只需设置相关环境变量即可：<code>export NUMBA_ENABLE_CUDASIM=1</code>。需要注意的是该模拟器通过cpu进行模拟调试，物理上的计算单元个数远小于gpu个数。所以通过模拟器运行的程序运行速度略慢于等同cpu多线程。而且在模拟器能够运行的程序，不一定能够在gpu设备上运行。因此只能做学习使用。</p>
<p>当环境搭建成功后，接下来就开始CUDA编程之旅吧~</p>
<h2
id="hello-world-初窥gpu中的线程网格grid线程块block和线程thread">"Hello,
World!":
初窥GPU中的线程网格（Grid），线程块（Block）和线程（Thread）</h2>
<p>环境配置成功后，本小节将通过在gpu设备上执行打印"Hello,
World!"程序，来初步了解gpu编程中的基本概念以及启动gpu函数的基本流程。具体程序如下。</p>
<details>
<summary>
代码："Hello, World!"
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> cuda</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cpu_print</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;cpu: &quot;hello world!&quot;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gpu_print</span>():</span><br><span class="line">    <span class="built_in">print</span>(cuda.blockIdx.x, cuda.threadIdx.x, <span class="string">&#x27;gpu: &quot;hello world!&quot;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    gpu_print[<span class="number">2</span>, <span class="number">4</span>]()</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    cpu_print()</span><br></pre></td></tr></table></figure>
输出: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">0 0 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">0 1 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">0 2 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">0 3 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">1 0 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">1 1 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">1 2 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">1 3 gpu: <span class="string">&quot;hello world!&quot;</span></span><br><span class="line">cpu: <span class="string">&quot;hello world!&quot;</span></span><br></pre></td></tr></table></figure>
</details>
<p>在numba中，cuda相关的函数被封装在<code>numba.cuda</code>中，可通过<code>from numba import cuda</code>引入。如果需要将代码在gpu上执行，需要将代码封装到函数中，并为函数加装饰器<code>@cuda.jit</code>。添加@cuda.jit装饰器的函数常备称为核函数(kernal)，由cpu调用，但只在gpu设备上执行。</p>
<p>具体而言，核函数运行在gpu的最小计算单元(core)上，每次运行由单个线程（Thread）所调用，多个线程组成一个线程块（Block），多个线程块组成线程网格（Grid）。粗略的讲，通常执行单个核函数的所有线程在一个线程网络中。该线程网络控制着线程块的数量和生存周期，而每个线程块又控制着其所属的线程的个数和生存周期。运行线程的计算单元被称为流处理器（SP:
Streaming Processor），多个线程组成的线程块运行在多流处理器上（SM:
Streaming
Multiprocessor），多个线程块组成的线程网格运行在一个gpu显卡上。</p>
<p>因此在核函数被cpu调用时，需要传入该核函数所在的线程网络中线程块的总体个数，以及每个线程块的线程个数。因此在执行<code>numba.cuda</code>中的核函数时需要定义线程块和线程的个数，如<code>kernal[num_block_per_grid, num_thread_per_block]()</code>。在本例中，<code>gpu_print[2, 4]()</code>表示使用2个线程块，每个线程块中使用4个线程去并行执行该核函数。因此共有<code>2*4=8</code>个线程并行执行该核函数，也就输出了8次<code>"hello world!"</code>。</p>
<p>核函数的启动方式是异步的：启动gpu核函数后，cpu不会等待gpu核函数执行完毕才执行下一行代码。必要时，需要调用<code>cuda.synchronize()</code>，告知cpu等待gpu执行完核函数后，再进行cpu端后续计算。这个过程被称为同步。如果不调用<code>cuda.synchronize()</code>函数，执行结果也将改变，<code>cpu: "hello world!"</code>将先被打印。虽然gpu核函数调用在前，但是程序并没有等待核函数执行完，而是继续执行后面的cpu_print函数。由于cpu调用gpu有一定的延迟，反而后面的<code>cpu_print</code>先被执行，因此<code>cpu_print</code>的结果先被打印了出来。</p>
<p>需要注意的是每个执行核函数的线程都知道其所在的线程块索引(block
index)和线程索引(thread index)，以及线程块和线程的个数(grid dimension
and block
dimension)。由于索引值可以通过计算等价于循环中的索引值，因此可以较为简单的通过使用cuda并行计算来取代程序中的顺序循环。线程（块）索引和个数可以有最多三个维度，可分别通过<code>x,y,z</code>进行访问。比如，在本例中我们通过<code>cuda.blockIdx.x</code>及<code>cuda.threadIdx.x</code>来得到该线程的线程块索引和线程索引，并且将其打印。</p>
<p>下文会通过并行计算矩阵加法来初步了解cuda多线程并行计算。</p>
<h2 id="矩阵加法-小试并行计算">矩阵加法： 小试并行计算</h2>
<p>上一小节通过"Hello,
World!"程序，对gpu核函数的运行流程以及cuda编程中的线程网格（Grid），线程块（Block）和线程（Thread）有了一个基本了解。本节将通过二维矩阵加法来进一步阐述cuda编程中的线程设置以及数据拷贝。具体程序如下。</p>
<details>
<summary>
代码：矩阵加法
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> cuda, jit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_cpu</span>(<span class="params">matrix_A, matrix_B, n_rows, n_cols</span>):</span><br><span class="line">    <span class="keyword">return</span> [[matrix_A[ridx][cidx] + matrix_B[ridx][cidx] <span class="keyword">for</span> cidx <span class="keyword">in</span> <span class="built_in">range</span>(n_cols)] <span class="keyword">for</span> ridx <span class="keyword">in</span> <span class="built_in">range</span>(n_rows)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numpy</span>(<span class="params">matrix_A, matrix_B, n_rows, n_cols</span>):</span><br><span class="line">    <span class="keyword">return</span> matrix_A + matrix_B</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_cpu_v2</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    <span class="keyword">for</span> ridx <span class="keyword">in</span> <span class="built_in">range</span>(n_rows):</span><br><span class="line">        <span class="keyword">for</span> cidx <span class="keyword">in</span> <span class="built_in">range</span>(n_cols):</span><br><span class="line">            matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line">    <span class="keyword">return</span> matrix_C</span><br><span class="line"></span><br><span class="line"><span class="meta">@jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numba_jit</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    <span class="keyword">for</span> ridx <span class="keyword">in</span> <span class="built_in">range</span>(n_rows):</span><br><span class="line">        <span class="keyword">for</span> cidx <span class="keyword">in</span> <span class="built_in">range</span>(n_cols):</span><br><span class="line">            matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line">    <span class="keyword">return</span> matrix_C</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numba_cuda</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    ridx = cuda.threadIdx.y + cuda.blockDim.y * cuda.blockIdx.y</span><br><span class="line">    cidx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ridx &lt; n_rows <span class="keyword">and</span> cidx &lt; n_cols:</span><br><span class="line">        matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numba_cuda_copy</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    ridx = cuda.threadIdx.y + cuda.blockDim.y * cuda.blockIdx.y</span><br><span class="line">    cidx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ridx &lt; n_rows <span class="keyword">and</span> cidx &lt; n_cols:</span><br><span class="line">        matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numba_cuda_v2</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    ridx = idx // n_cols</span><br><span class="line">    cidx = idx %  n_cols</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ridx &lt; n_rows <span class="keyword">and</span> cidx &lt; n_cols:</span><br><span class="line">        matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    n_row, n_col = <span class="number">1080</span>, <span class="number">1920</span></span><br><span class="line"></span><br><span class="line">    arr_A, arr_B = [[[random.random() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_col)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_row)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    arr_cpu = matrix_add_cpu(arr_A, arr_B, n_row, n_col)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process time on cpu : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    arr_A, arr_B = np.array(arr_A), np.array(arr_B)</span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    arr_numpy = matrix_add_numpy(arr_A, arr_B, n_row, n_col)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (arr_numpy - np.array(arr_cpu)).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numpy : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    arr_C = arr_B.copy()</span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    arr_cpu_v2 = matrix_add_cpu_v2(arr_A, arr_B, arr_C, n_row, n_col)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (arr_numpy - arr_cpu_v2).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on cpu v2 : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    arr_n_jit = matrix_add_numba_jit(arr_A, arr_B, arr_C, n_row, n_col)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (arr_numpy - arr_n_jit).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba jit : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    threadsperblock = (<span class="number">16</span>, <span class="number">16</span>)</span><br><span class="line">    blockspergrid_x = math.ceil(n_col / threadsperblock[<span class="number">0</span>])</span><br><span class="line">    blockspergrid_y = math.ceil(n_row / threadsperblock[<span class="number">1</span>])</span><br><span class="line">    blockspergrid = (blockspergrid_x, blockspergrid_y)</span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    matrix_add_numba_cuda[blockspergrid, threadsperblock](arr_A, arr_B, arr_C, n_row, n_col)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (arr_numpy - arr_C).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    d_arr_A, d_arr_B, d_arr_C = cuda.to_device(arr_A), cuda.to_device(arr_B), cuda.to_device(arr_C)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    matrix_add_numba_cuda_copy[blockspergrid, threadsperblock](d_arr_A, d_arr_B, d_arr_C, n_row, n_col)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    arr_C = d_arr_C.copy_to_host()</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    <span class="keyword">if</span> (arr_numpy - arr_C).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda with copied data : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    threadsperblock = <span class="number">256</span></span><br><span class="line">    blockspergrid   = math.ceil((n_col*n_row)/threadsperblock)</span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    matrix_add_numba_cuda_v2[blockspergrid, threadsperblock](d_arr_A, d_arr_B, d_arr_C, n_row, n_col)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    arr_C = d_arr_C.copy_to_host()</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    <span class="keyword">if</span> (arr_numpy - arr_C).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda with copied data : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br></pre></td></tr></table></figure>
<p>输出1: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">process time on cpu : 203.750ms</span><br><span class="line">process time on numpy : 2.630ms</span><br><span class="line">process time on cpu v2 : 1334.258ms</span><br><span class="line">process time on numba jit : 235.476ms</span><br><span class="line">process time on numba cuda : 217.982ms</span><br><span class="line">process time on numba cuda with copied data : 76.042ms</span><br><span class="line">process time on numba cuda v2 with copied data : 75.180ms</span><br></pre></td></tr></table></figure></p>
输出2： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">process time on cpu : 245.238ms</span><br><span class="line">process time on numpy : 2.766ms</span><br><span class="line">process time on cpu v2 : 1410.334ms</span><br><span class="line">process time on numba jit (1st): 234.586ms</span><br><span class="line">process time on numba jit (2nd): 3.086ms</span><br><span class="line">process time on numba cuda (1st): 234.172ms</span><br><span class="line">process time on numba cuda (2nd): 15.431ms</span><br><span class="line">process time on numba cuda with copied data (1st): 80.449ms</span><br><span class="line">process time on numba cuda with copied data (2nd): 0.642ms</span><br><span class="line">process time on numba cuda v2 with copied data (1st): 78.265ms</span><br><span class="line">process time on numba cuda v2 with copied data (2nd): 0.538ms</span><br></pre></td></tr></table></figure>
</details>
<p>当计算独立时，并行的cuda核函数可以简单取代程序中的循环并实现巨大的提速。在本例中，纯python编程想要计算两矩阵相加，必须通过循环来遍历矩阵上的所有点来进行计算。正如上一小节所讲，在cuda核函数中的索引值等价于循环中的索引值，python程序中的通过顺序循环遍历矩阵就可以被cuda中的多线程核函数并行遍历矩阵所取代。在核函数中，线程可以通过计算索引来访问到对应的点的位置。比如，循环中的行和列的索引值<code>ridx</code>,<code>cidx</code>
在核函数可通过线程（块）索引和个数来计算得到<code>ridx = cuda.threadIdx.y + cuda.blockDim.y * cuda.blockIdx.y</code>，<code>cidx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</code>。如程序所示，该核函数中只计算了矩阵中一个点计算加法。因此在执行该gpu函数时，每个线程只为矩阵中一个点计算加法，多个线程并行运行，进而实现了快速高并发的并行计算。可以看到，相较于纯python编程，cuda并行计算可提速3倍到18倍。但有一点值得奇怪，如果该函数在运行第二次时，其速度为0.8ms左右，也就是存在264～1654倍的提速。所以可能在numba中第一遍速度较慢是由于numba的动态编译所导致的，具体原因尚需细查。</p>
<p>上小节提到线程块运行在多流处理器上，线程运行在流处理器上。在物理显卡中，多流处理器所包含的流处理器的数量是固定的，对目前市场上的主流显卡，多流处理器一般包含1024或512个流处理器。因此，在设置线程个数时，必须小于等于每个多流处理器包含流处理器的个数，也就是要小于或等于1024或512。所以一般线程个数在程序中常作为常量存在，如在本例线程的个数被固定为<code>(16, 16)</code>，也就是256个线程。
并且，多流处理器在物理上通过线程束（warp）来分组调度流处理器，每个线程束调度的线程个数也是固定的，一般为32个。每个线程束中所有流处理器（32个）是一起工作的，执行相同的指令。如果没有这么多的流处理器需要工作，那么这个线程束中的一些流处理器是不工作的。为了使每个线程束中所有的线程都在工作，当进行并行计算时，线程数尽量为32的倍数。如在本例中，线程的个数是256（<code>(16, 16)</code>），也就是32的8倍。如果线程数设置为1的话，线程束会生成掩码，使得32个线程中只有一个线程在真正执行，其他31个线程会进入静默状态。这样计算资源就会浪费，在计算量较大时，执行效率就明显变低了。</p>
<p>由于线程的个数在程序中常为常量，为了能够取代所有循环，一般线程块的个数可以由总循环次数除以线程个数，并向上取整。如在本例中，为了能够遍历到矩阵中所有点，线程块个数被设置为<code>blockspergrid_x = math.ceil(n_col / threadsperblock[0])</code>,
<code>blockspergrid_y = math.ceil(n_row / threadsperblock[1])</code>，在本例中也就是<code>(120,68)</code>，也就是8160个线程块。但向上取整存在一个问题，通过该设置所生成的线程个数大于本身的循环次数，即<code>(8160*256 &gt; 1920*1080)</code>，所以在核函数中一般需要进行判断来防止索引溢出。如本例中的<code>if ridx &lt; n_rows and cidx &lt; n_cols:</code>。上小节将到了线程（块）个数最多可定义为三个维度，但每个维度都有可能向上取整，维度越多造成资源浪费的可能性越大。这也就导致了虽然多维线程（块）个数在编程中更容易理解，但为了减少资源浪费的可能，在cuda编程中更建议用单个维度（一维）来定义线程（块）个数。</p>
<p>上小节说，核函数被cpu调用，被gpu执行。再延伸一点，核函数被gpu执行所调用的数据需存储在gpu显存中而非cpu内存中。所以在gpu编程中，常常需要先将输入数据从cpu内存拷贝到gpu显存中，也需要将gpu输出结果从gpu显存拷贝回cpu内存中。在<code>numba.cuda</code>中，如果发现传入数据在cpu内存上时，在执行核函数前，会自动将所有输入数据从cpu内存拷贝到gpu显存中，并在核函数结束后，将所有输入数据从gpu显存同步回cpu内存。但这样就导致了不必要的拷贝和额外的时间开销，如在本例中<code>matrix_A</code>和<code>matrix_B</code>的是不需要拷贝回cpu内存的。所以在cuda编程中，建议通过<code>cuda.to_device()</code>将输入数据从cpu内存拷贝到gpu显存中，结果并将结果通过<code>arr.copy_to_host()</code>从gpu显存拷贝回到cpu内存中。如果想要避免结果数组从cpu内存拷贝到gpu显存造成的额外开销，也可以通过<code>cuda.device_array()</code>在gpu显存中一个空向量来实现。在本例中，在执行核函数时，手动拷贝数据的执行效率要比自动拷贝数据效率要高的多。</p>
<p>此外，因为gpu的传输带宽较大，一般多次传输小数据的速率要低于单次传输同等数据的速率。所以在cpu与gpu相互拷贝数据时，尽量采用单次传输。但当数据较大时，gpu无法同时计算所有的数据，这时分批拷贝并计算就可以进一步提速cuda核函数。</p>
<p>在下一小节，将通过分批处理来进一步优化矩阵加法，并阐述了gpu编程中流(stream)的概念。</p>
<h2 id="分批处理矩阵流stream">分批处理矩阵：流(stream)</h2>
<p>上节讲到，当数据计算量较大时，gpu无法同时计算所有的数据，这时候gpu可以将计算任务分批放在一个队列中，排队顺序执行。这种按照队列顺序流水线处理的操作叫做流(stream)。这一小节依然进行矩阵加法，但将计算量是上一小节的100倍，并采用了流进行分批处理。具体代码如下。</p>
<details>
<summary>
代码：矩阵加法-多流
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> cuda</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numba_cuda</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    ridx = idx // n_cols</span><br><span class="line">    cidx = idx %  n_cols</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ridx &lt; n_rows <span class="keyword">and</span> cidx &lt; n_cols:</span><br><span class="line">        matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numba_cuda_queue</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    ridx = idx // n_cols</span><br><span class="line">    cidx = idx %  n_cols</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ridx &lt; n_rows <span class="keyword">and</span> cidx &lt; n_cols:</span><br><span class="line">        matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_add_numba_cuda_stream</span>(<span class="params">matrix_A, matrix_B, matrix_C, n_rows, n_cols</span>):</span><br><span class="line">    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    ridx = idx // n_cols</span><br><span class="line">    cidx = idx %  n_cols</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ridx &lt; n_rows <span class="keyword">and</span> cidx &lt; n_cols:</span><br><span class="line">        matrix_C[ridx][cidx] = matrix_A[ridx][cidx] + matrix_B[ridx][cidx]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    n_row, n_col = <span class="number">10800</span>, <span class="number">19200</span></span><br><span class="line"></span><br><span class="line">    arr_A, arr_B, arr_C = np.random.random((n_row, n_col)), np.random.random((n_row, n_col)), np.random.random((n_row, n_col))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># basic one time</span></span><br><span class="line">    threadsperblock = <span class="number">256</span></span><br><span class="line">    blockspergrid   = math.ceil((n_col*n_row)/threadsperblock)</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    d_arr_A, d_arr_B, d_arr_C = cuda.to_device(arr_A), cuda.to_device(arr_B), cuda.to_device(arr_C)</span><br><span class="line">    matrix_add_numba_cuda[blockspergrid, threadsperblock](d_arr_A, d_arr_B, d_arr_C, n_row, n_col)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    arr_result = d_arr_C.copy_to_host()</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># queue</span></span><br><span class="line">    n_streams     = <span class="number">4</span></span><br><span class="line">    seg_row       = n_row // n_streams</span><br><span class="line">    blockspergrid = math.ceil((seg_row* n_col) / threadsperblock)</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_streams):</span><br><span class="line">        d_arr_A = cuda.to_device(arr_A[i * seg_row : (i + <span class="number">1</span>) * seg_row])</span><br><span class="line">        d_arr_B = cuda.to_device(arr_B[i * seg_row : (i + <span class="number">1</span>) * seg_row])</span><br><span class="line">        cuda.synchronize()</span><br><span class="line">        matrix_add_numba_cuda_queue[blockspergrid, threadsperblock](</span><br><span class="line">                d_arr_A,</span><br><span class="line">                d_arr_B,</span><br><span class="line">                d_arr_C[i * seg_row : (i + <span class="number">1</span>) * seg_row],</span><br><span class="line">                seg_row,</span><br><span class="line">                n_col)</span><br><span class="line">        cuda.synchronize()</span><br><span class="line">        arr_C[i * seg_row : (i + <span class="number">1</span>) * seg_row] = d_arr_C[i * seg_row : (i + <span class="number">1</span>) * seg_row].copy_to_host()</span><br><span class="line">        cuda.synchronize()</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (arr_result - arr_C).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda queue: &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># stream</span></span><br><span class="line">    stream_list   = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">0</span>, n_streams):</span><br><span class="line">        stream = cuda.stream()</span><br><span class="line">        stream_list.append(stream)</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_streams):</span><br><span class="line">        d_arr_A = cuda.to_device(arr_A[i * seg_row : (i + <span class="number">1</span>) * seg_row], stream=stream_list[i])</span><br><span class="line">        d_arr_B = cuda.to_device(arr_B[i * seg_row : (i + <span class="number">1</span>) * seg_row], stream=stream_list[i])</span><br><span class="line">        matrix_add_numba_cuda_stream[blockspergrid, threadsperblock, stream_list[i]](</span><br><span class="line">                d_arr_A,</span><br><span class="line">                d_arr_B,</span><br><span class="line">                d_arr_C[i * seg_row : (i + <span class="number">1</span>) * seg_row],</span><br><span class="line">                seg_row,</span><br><span class="line">                n_col)</span><br><span class="line">        arr_C[i * seg_row : (i + <span class="number">1</span>) * seg_row] = d_arr_C[i * seg_row : (i + <span class="number">1</span>) * seg_row].copy_to_host(stream=stream_list[i])</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (arr_result - arr_C).<span class="built_in">max</span>() &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda stream: &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br></pre></td></tr></table></figure>
<p>输出1: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">process time on numba cuda : 1180.036ms</span><br><span class="line">process time on numba cuda queue: 1019.919ms</span><br><span class="line">process time on numba cuda stream: 973.997ms</span><br></pre></td></tr></table></figure></p>
<p>输出2： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">process time on numba cuda (1st): 1187.603ms</span><br><span class="line">process time on numba cuda (2nd): 883.670ms</span><br><span class="line">process time on numba cuda queue (1st): 1064.817ms</span><br><span class="line">process time on numba cuda queue (2nd): 932.134ms</span><br><span class="line">process time on numba cuda stream (1st): 959.764ms</span><br><span class="line">process time on numba cuda stream (2nd): 887.833ms</span><br></pre></td></tr></table></figure></p>
</details>
<pre class="mermaid">
gantt
title Default vs Queue vs Stream
dateFormat  ss
   axisFormat  %S
section Default
Host2Device      : a1, 0s, 3s
Kernal           : a2, after a1 , 3s
   Device2Host      : after a2 , 3s

section Queue
Host2Device1     : 0s, 1s
Kernal1          : 1s
   Device2Host1     : 1s
Host2Device2     : 1s
Kernal2          : 1s
   Device2Host2     : 1s
Host2Device3     : 1s
Kernal3          : 1s
   Device2Host3     : 1s

section Stream
Host2Device1     : b1, 0s, 1s
Kernal1          : b2, after b1 , 1s
   Device2Host1     : after b2 , 1s
Host2Device2     : after b1,  1s
Kernal2          : b3, after b2, 1s
   Device2Host2     : after b3 , 1s
Host2Device3     : after b2,  1s
Kernal3          : b4, after b3, 1s
   Device2Host3     : after b4 , 1s
</pre>
<p>由于gpu的硬件特性，cuda中的很多操作是相互独立的，比如核函数的计算，cpu内存与gpu显存间的相互拷贝等。针对这种互相独立的硬件架构，cuda使用多流(multistream)作为一种高并发的方案：把一个大任务拆分开放到多个流中，每次只对一部分数据进行拷贝、计算和回写，并把这个流程做成流水线。这样数据拷贝和核函数计算重叠的时间是重叠的，进而获得性能的提升。如在本例中，通过cuda流处理比简单的队列处理要略快一些。</p>
<p>既然要形成多流的队列，那么队列中的每一步操作都需要知道自己在流。因此在cuda编程中，需要先创建每个流的对象，再把流对象赋值给每一步操作。在numba中，流对象可通过<code>cuda.stream()</code>来创建；执行核函数时，需要与线程块和线程个数一起定义，如<code>kernal[num_block_per_grid, num_thread_per_block, stream]()</code>；而在拷贝数据时，也需要将其加入拷贝函数，如<code>cuda.to_device(stream=stream)</code>和<code>arr.copy_to_host(stream=stream)</code>。这样，每个流水线可以知道自己所需要执行的步骤了。当不指定具体流对象时，这些操作会在默认的流上执行。</p>
<p>每个流水线是顺序执行的，但非默认的流水线是异步操作的，也就是说先创建的流水线可能后完成。默认流有阻塞的作用。如果调用默认流，那么默认流会等非默认流都执行完才能执行；同样，默认流执行完，才能再次执行其他非默认流。另外，流不宜分配过多，当流过多时，有可能在每个流水线上的核函数计算时间代价会小于单次数据拷贝的时间（如内存到显存或显存到内存）。由于每种操作自身时不独立的，所以其必须等待其他的流完成数据拷贝操作才可以开始自己的数据拷贝操作。这样反而会导致流水线处理的执行效率变低。在实践中，可能需要硬件设备的执行效率和核函数的计算量来微调流的个数，进而达到相对好的表现。</p>
<p>关于矩阵加法的例子先到这里，下面的小节将通过矩阵求和，来阐述并行归约（Reduction）算法及其优化过程中的线程束分化和内存访问。</p>
<h2 id="矩阵求和并行归约reduction">矩阵求和：并行归约（Reduction）</h2>
<p>在之前的矩阵加法中，每个点的计算是相互独立的，各个线程不需要考虑其他线程的计算结果，所以其循环替代和核函数计算相对简单直观。但在很多任务中，循环需要依赖上一步的执行结果，替换此类核函数相对复杂了。本小节将引入矩阵求和，来简单介绍通过并行归约算法解决二元操作问题。其代码如下：</p>
<details>
<summary>
代码：矩阵求和
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> cuda, jit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_sum_numpy</span>(<span class="params">matrix, n_rows, n_cols</span>):</span><br><span class="line">    <span class="keyword">return</span> matrix.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_sum_cpu</span>(<span class="params">matrix, n_rows, n_cols</span>):</span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> ridx <span class="keyword">in</span> <span class="built_in">range</span>(n_rows):</span><br><span class="line">        <span class="keyword">for</span> cidx <span class="keyword">in</span> <span class="built_in">range</span>(n_cols):</span><br><span class="line">            res += matrix[ridx][cidx]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="meta">@jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_sum_numba_jit</span>(<span class="params">matrix, n_rows, n_cols</span>):</span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> ridx <span class="keyword">in</span> <span class="built_in">range</span>(n_rows):</span><br><span class="line">        <span class="keyword">for</span> cidx <span class="keyword">in</span> <span class="built_in">range</span>(n_cols):</span><br><span class="line">            res += matrix[ridx][cidx]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_sum_reduce_numba_cuda</span>(<span class="params">matrix, res, max_stride_iter, n_rows, n_cols</span>):</span><br><span class="line">    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    volume = n_rows * n_cols</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> idx &lt; volume:</span><br><span class="line">        ridx = idx // n_cols</span><br><span class="line">        cidx = idx %  n_cols</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(max_stride_iter):</span><br><span class="line">            stride = <span class="number">2</span>**s</span><br><span class="line">            <span class="keyword">if</span> (cuda.threadIdx.x % (<span class="number">2</span> * stride)) == <span class="number">0</span>:</span><br><span class="line">                idx_s = idx + stride</span><br><span class="line">                <span class="keyword">if</span> idx_s &lt; volume:</span><br><span class="line">                    ridx_s = idx_s // n_cols</span><br><span class="line">                    cidx_s = idx_s %  n_cols</span><br><span class="line">                    matrix[ridx][cidx] += matrix[ridx_s][cidx_s]</span><br><span class="line">            cuda.syncthreads()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> cuda.threadIdx.x == <span class="number">0</span>:</span><br><span class="line">        res[cuda.blockIdx.x] = matrix[ridx][cidx]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_sum_reduce_numba_cuda_v2</span>(<span class="params">matrix, res, max_stride_iter, n_rows, n_cols</span>):</span><br><span class="line">    blockIdx = cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    idx = cuda.threadIdx.x + blockIdx</span><br><span class="line">    volume = n_rows * n_cols</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> idx &lt; volume:</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(max_stride_iter):</span><br><span class="line">            stride = <span class="number">2</span>**s</span><br><span class="line">            idx =  <span class="number">2</span> * stride * cuda.threadIdx.x</span><br><span class="line">            <span class="keyword">if</span> idx &lt; cuda.blockDim.x:</span><br><span class="line">                idx = idx + blockIdx</span><br><span class="line">                idx_s = idx + stride</span><br><span class="line">                <span class="keyword">if</span> idx &lt; volume <span class="keyword">and</span> idx_s &lt; volume:</span><br><span class="line">                    ridx = idx // n_cols</span><br><span class="line">                    cidx = idx %  n_cols</span><br><span class="line">                    ridx_s = idx_s // n_cols</span><br><span class="line">                    cidx_s = idx_s %  n_cols</span><br><span class="line">                    matrix[ridx][cidx] += matrix[ridx_s][cidx_s]</span><br><span class="line">            cuda.syncthreads()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> cuda.threadIdx.x == <span class="number">0</span>:</span><br><span class="line">        res[cuda.blockIdx.x] = matrix[ridx][cidx]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_sum_reduce_numba_cuda_v3</span>(<span class="params">matrix, res, max_stride_iter, n_rows, n_cols</span>):</span><br><span class="line">    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x</span><br><span class="line">    volume = n_rows * n_cols</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> idx &lt; volume:</span><br><span class="line">        ridx = idx // n_cols</span><br><span class="line">        cidx = idx %  n_cols</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_stride_iter):</span><br><span class="line">            stride = cuda.blockDim.x // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> cuda.threadIdx.x &lt; stride:</span><br><span class="line">                idx_s = idx + stride</span><br><span class="line">                <span class="keyword">if</span> idx_s &lt; volume:</span><br><span class="line">                    ridx_s = idx_s // n_cols</span><br><span class="line">                    cidx_s = idx_s %  n_cols</span><br><span class="line">                    matrix[ridx][cidx] += matrix[ridx_s][cidx_s]</span><br><span class="line">            cuda.syncthreads()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> cuda.threadIdx.x == <span class="number">0</span>:</span><br><span class="line">        res[cuda.blockIdx.x] = matrix[ridx][cidx]</span><br><span class="line"></span><br><span class="line"><span class="meta">@cuda.reduce</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_sum_reduce_numba_cuda_reduce</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    n_row, n_col = <span class="number">1080</span>, <span class="number">1920</span></span><br><span class="line">    arr = np.random.random((n_row, n_col))</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    res_numpy = matrix_sum_numpy(arr, n_row, n_col)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;process time on numpy : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    res_cpu = matrix_sum_cpu(arr, n_row, n_col)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (res_numpy - res_cpu) &lt; <span class="number">1e-6</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on cpu : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    res_n_jit = matrix_sum_numba_jit(arr, n_row, n_col)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (res_numpy - res_n_jit) &lt; <span class="number">1e-6</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba jit : &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># numba cuda v1, v2, v3 and reduce version</span></span><br><span class="line">    threadsperblock = <span class="number">1024</span></span><br><span class="line">    blockspergrid   = math.ceil((n_col*n_row)/threadsperblock)</span><br><span class="line">    max_stride_iter = math.ceil(math.log2(threadsperblock))</span><br><span class="line">    block_res_n_cuda = np.zeros(blockspergrid)</span><br><span class="line">    d_arr = cuda.to_device(arr)</span><br><span class="line">    d_block_res_n_cuda = cuda.to_device(block_res_n_cuda)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    matrix_sum_reduce_numba_cuda[blockspergrid, threadsperblock](d_arr, d_block_res_n_cuda, max_stride_iter, n_row, n_col)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    block_res_n_cuda = d_block_res_n_cuda.copy_to_host()</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    res_n_cuda = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> res <span class="keyword">in</span> block_res_n_cuda:</span><br><span class="line">        res_n_cuda += res</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (res_numpy - res_n_cuda) &lt; <span class="number">1e-6</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda: &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    matrix_sum_reduce_numba_cuda_v2[blockspergrid, threadsperblock](d_arr, d_block_res_n_cuda, max_stride_iter, n_row, n_col)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    block_res_n_cuda = d_block_res_n_cuda.copy_to_host()</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    res_n_cuda = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> res <span class="keyword">in</span> block_res_n_cuda:</span><br><span class="line">        res_n_cuda += res</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (res_numpy - res_n_cuda) &lt; <span class="number">1e-6</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda v2: &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    matrix_sum_reduce_numba_cuda_v3[blockspergrid, threadsperblock](d_arr, d_block_res_n_cuda, max_stride_iter, n_row, n_col)</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    block_res_n_cuda = d_block_res_n_cuda.copy_to_host()</span><br><span class="line">    cuda.synchronize()</span><br><span class="line">    res_n_cuda = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> res <span class="keyword">in</span> block_res_n_cuda:</span><br><span class="line">        res_n_cuda += res</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (res_numpy - res_n_cuda) &lt; <span class="number">1e-6</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba cuda v3: &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    arr_1d = arr.reshape(-<span class="number">1</span>)</span><br><span class="line">    d_arr_1d = cuda.to_device(arr_1d)</span><br><span class="line">    elapsed_time = time.time()</span><br><span class="line">    res_n_cuda_reduce = matrix_sum_reduce_numba_cuda_reduce(d_arr_1d)</span><br><span class="line">    elapsed_time = time.time() - elapsed_time</span><br><span class="line">    <span class="keyword">if</span> (res_numpy - res_n_cuda_reduce) &lt; <span class="number">1e-6</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;process time on numba reduce: &#123;:.03f&#125;ms&quot;</span>.<span class="built_in">format</span>(elapsed_time * <span class="number">1000</span>))</span><br></pre></td></tr></table></figure>
<p>输出1: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">process time on numpy : 0.820ms</span><br><span class="line">process time on cpu : 566.166ms</span><br><span class="line">process time on numba jit : 187.324ms</span><br><span class="line">process time on numba cuda: 208.259ms</span><br><span class="line">process time on numba cuda v2: 137.212ms</span><br><span class="line">process time on numba cuda v3: 120.333ms</span><br><span class="line">process time on numba reduce: 376.588ms</span><br></pre></td></tr></table></figure></p>
<p>输出2: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">process time on numpy : 0.871ms</span><br><span class="line">process time on cpu : 567.084ms</span><br><span class="line">process time on numba jit (1st): 236.218ms</span><br><span class="line">process time on numba jit (2nd): 2.202ms</span><br><span class="line">process time on numba cuda (1st): 252.695ms</span><br><span class="line">process time on numba cuda (2nd): 1.662ms</span><br><span class="line">process time on numba cuda v2 (1st): 158.547ms</span><br><span class="line">process time on numba cuda v2 (2nd): 1.468ms</span><br><span class="line">process time on numba cuda v3 (1st): 130.770ms</span><br><span class="line">process time on numba cuda v3 (2nd): 1.101ms</span><br><span class="line">process time on numba reduce (1st): 434.946ms</span><br><span class="line">process time on numba reduce (2nd): 0.686ms</span><br></pre></td></tr></table></figure></p>
</details>
<p>并行归约（Reduction）是一种基础的并行算法。该算法常处理如下问题：假设有N个输入数据，使用一个符合结合律的二元操作符作用其上，最终生成1个结果。这个二元操作符可以是求和、取最大、取最小、平方、逻辑与或等等。本例以加法为例。这种问题的最基本的解决思路就是串行遍历，如示例代码中的<code>matrix_sum_cpu</code>函数。当将问题转化为并行计算时，由于加法的交换律和结合律，矩阵可以以任意顺序求和，其解决思路可以为：首先把输入数组划分为更小的数据块，之后用一个线程计算一个数据块的部分和，最后把所有部分和再求和得出最终结果。这种思路就被称为并行归约。相较于串行计算，并行归约的时间复杂度由<code>O(N)</code>变为<code>O(logN)</code>。由于并行归约非常经典，又在cuda编程中常常使用，numba.cuda本身就通过<code>cuda.reduce</code>实现了为1维数组的并行归约算法，其相关调用可参考本例中的<code>matrix_sum_reduce_numba_cuda_reduce</code>函数。</p>
<p>在本例中，并行归约在numba.cuda上的具体实现可参考<code>matrix_sum_reduce_numba_cuda</code>函数。具体而言，核函数循环stride，stride的上限为线程块中的线程个数，每次循环stride*2。当线程所索引到的数据对步长取余为0时，将线程所索引到的数据和与该数据距离stride的数据进行求和。最后返回该线程块的求和结果，并在cpu为所有线程块的结果求和。之所以只求得线程块的和，是因为核函数只能在每一个线程块中实现同步线程进度。具体而言，在并行归约中，循环中的每一步都需要上一步全部完成才能得到正确结果。因此如果想实现全局求和，需要同步每一个线程块的每一个线程来确认都已完成该步骤。而基于上面小节得知，不同的线程块的开始和结束是不一致的，所以在cuda编程中核函数无法同步不同线程块，甚至需要分批计算。假如某核函数需要10个线程块，但gpu只能并行计算5个线程块，这10个线程块将分成两批进行计算，也就无法为这10个线程块的所有线程达到同一时间的同步。因此核函数只能在每一个线程块中实现同步，无法跨线程块同步线程进度。在numba.cuda中，线程块内线程进度的同步通过<code>cuda.syncthreads()</code>来完成。</p>
<p>在本例的<code>matrix_sum_reduce_numba_cuda</code>函数中，每次循环只有线程索引为是stride的倍数的线程在进行执行，其他线程则保持静默。这样就导致在每一个线程束中只有稀疏的线程在执行，这种情况被称为线程束分化。但由于硬件设计，调度会以一整个线程束为单位进行，所以影响了程序的效率。线程束分化可以通过重新组织线程索引来解决。如本例<code>matrix_sum_reduce_numba_cuda_v2</code>函数所示，通过重新组织线程索引，可以保证在每一个block中一部分线程束的所有线程都在活跃，而另一部分线程束的所有线程都在静默。如在第一轮迭代，前16个线程束执行计算，后16个线程束什么都不做。通过简单整理线程索引，可以提高程序效率，如本例v2比v1执行速度提升了1.5倍。</p>
<p>此外，对全局内存的访问尽量进行合并访问与存储，能够达到尽量最大的带宽，也能够提升程序效率。比如在本例<code>matrix_sum_reduce_numba_cuda_v2</code>函数，每一循环所访问的数据索引不仅由线程索引决定，也由循环的跨度决定，即<code>idx =  2 * stride * cuda.threadIdx.x</code>。这就导致每次循环依据索引所访问到的数据并不连续，其跨度为stride。为了缓解这种现象，在并行归约中可以重新组织配对方法，进而让对内存的访问更加集中。如本例中<code>matrix_sum_reduce_numba_cuda_v3</code>所示，通过交错配对的方法，使得结果每次循环中只访问和存储到统一地址，进而提升了访问效率。如本例v3比v2执行速度提升了1.14倍。</p>
<p>（未完待续）</p>
<h2 id="参考">参考</h2>
<p>在撰写本文时，大量的参考了官方文档和其他博客，收益良多。观点表述如有雷同，可视为出自原作者。相关参考链接如下：
* <a href="http://numba.pydata.org/numba-doc/latest/">numba document</a>
* <a href="https://lulaoshi.info/gpu/">Python GPU快速教程</a> * <a
href="https://zhuanlan.zhihu.com/c_1188568938097819648">CUDA编程入门</a></p>
<p>眼过千遍，不如手过一遍。希望在阅读本文之后能够自己复现出来上述cuda代码。共勉。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numba</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>Numba: 简单装饰器加速python代码</title>
    <url>/zh/2020/07/04/zh/numba_python/</url>
    <content><![CDATA[<p>简单易用与运行效率低是贴在python身上的两大标签。开发人员一方面对其简单的语法和丰富的库爱不释手，一方面又对其由于动态编译和解释执行带来的较低的运行效率和GIL带来的多线程难扩展的情况深恶痛绝。为了解决这些python中的固有问题，一些解释器如cython尝试对一些函数提前编译进而提高执行效率。但绝大多数的解释器或库函数的语法非常不pythonic，而且也不能够做到即插即用。本文简单介绍了如何通过numba库，为python函数装饰器的方式来对python函数进行加速。为读者提供一中，简单易用，灵活编译方式去解决python的固有问题，提高python代码的执行效率。</p>
<span id="more"></span>
<h2 id="环境配置">环境配置</h2>
<p>为了简化环境配置，本文中的编程环境将全部由conda配置，并在conda的虚拟环境中测试。所涉及的依赖库分别是<code>numba</code>和<code>numpy</code>。相关环境可以通过以下语令进行配置。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n numba-python python=3.7</span><br><span class="line">conda activate numba-python</span><br><span class="line">conda install numba numpy</span><br></pre></td></tr></table></figure>
<h2 id="基本概念">基本概念</h2>
<h3
id="编译型语言compiled-language解释型语言interpreted-language和即时编译just-in-time">编译型语言（Compiled
language），解释型语言（Interpreted
language）和即时编译（Just-In-Time）</h3>
<p>用高级语言编写的程序一般可通过由解释器（Interpreter）直接执行，或由编译器（Compiler）编译成机械码再执行。由解释器直接执行的高级语言称为解释型语言（Interpreted
language），其执行流程一般为：（解释型语言-&gt;程序运行-&gt;字节码-&gt;机械码），常见的解释型语言有Perl，Python，MATLAB和Ruby。需要通过编译器进行提前编译（AoT:
ahead of time）再执行的高级语言称为编译型语言（Compiled
language），其执行流程一般为：（编译型语言-&gt;机械码-&gt;程序运行），常见的编译型语言有c和c++。由于解释型语言可直接运行，其代码的灵活性相对更高。但在一般情况下，解释型语言需要边编译边运行，所以其执行效率相对于编译型语言较低。尤其对于部分反复执行的代码，解释型语言常需要对其进行反复编译。即时编译（Just-In-Time）结合了编译器的速度和解释器的灵活性，并允许自适应优化。</p>
<p>python是一种典型的解释型语言。在执行时，解释器首先将程序的字节码存储到.pyc，在将字节码发送到python虚拟机上进一步的解释执行字节码。如果程序未发生变化，python的字节码并不需要反复生成，但在python虚拟机上的解释步骤是需要反复执行的。在python
numba中，可将numba.jit的函数在第一次执行时生成的机械码，进而在该函数可以直接调用生成的机械码而省去反复解释的过程，进而达到与编译型语言相似的速度。</p>
<h3 id="装饰器decorator">装饰器（Decorator）</h3>
<p>装饰器是一种常见的设计模式，其允许向一个现有的对象添加新的功能，同时又不改变其结构。在python中，装饰器可以通过函数或类的形式定义，并通过<code>@decorator</code>的方式调用，一些常见的装饰器结构定义和调用方式可见如下代码。</p>
<details>
<summary>
代码：装饰器
</summary>
<p>通过函数定义装饰器 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef0</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;simplist decorator, with wrong func name&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        startt = time.time()</span><br><span class="line">        result = func(*args, **kw)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef1</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;decorator with correct func name&quot;&quot;&quot;</span></span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        startt = time.time()</span><br><span class="line">        result = func(*args, **kw)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef2</span>(<span class="params">num_runs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;decorator with param&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decorator</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">        @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">            startt = time.time()</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_runs):</span><br><span class="line">                result = func(*args, **kw)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;(time.time()-startt)/num_runs:<span class="number">0.6</span>f&#125;</span>s (Avg over <span class="subst">&#123;num_runs&#125;</span> runs)&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef3</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;decorator with and without param&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(kw)==<span class="number">0</span>:</span><br><span class="line">        func = args[<span class="number">0</span>]</span><br><span class="line"><span class="meta">        @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">            startt = time.time()</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(args) == <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">len</span>(kw)!=<span class="number">0</span>:</span><br><span class="line">        num_runs = kw[<span class="string">&quot;num_runs&quot;</span>] <span class="keyword">if</span> <span class="string">&quot;num_runs&quot;</span> <span class="keyword">in</span> kw <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        warmup   = kw[<span class="string">&quot;warmup&quot;</span>] <span class="keyword">if</span> <span class="string">&quot;warmup&quot;</span> <span class="keyword">in</span> kw <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">decorator</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">            @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">                <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(warmup):</span><br><span class="line">                    result = func(*args, **kw)</span><br><span class="line">                startt = time.time()</span><br><span class="line">                <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_runs):</span><br><span class="line">                    result = func(*args, **kw)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;(time.time()-startt)/num_runs:<span class="number">0.6</span>f&#125;</span>s (Avg over <span class="subst">&#123;num_runs&#125;</span> runs)&quot;</span>)</span><br><span class="line">                <span class="keyword">return</span> result</span><br><span class="line">            <span class="keyword">return</span> wrapper</span><br><span class="line">        <span class="keyword">return</span> decorator</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Params for decorator are not expected!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef4</span>(<span class="params">func=<span class="literal">None</span>, num_runs=<span class="number">1</span>, warmup=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;decorator with and without param, a more flatten way&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> func:</span><br><span class="line">        <span class="keyword">return</span> functools.partial(timef4, num_runs=num_runs, warmup=warmup)</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(warmup):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        startt = time.time()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_runs):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        <span class="keyword">if</span> num_runs == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;(time.time()-startt)/num_runs:<span class="number">0.6</span>f&#125;</span>s (Avg over <span class="subst">&#123;num_runs&#125;</span> runs)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f0</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef1</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f1</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef2(<span class="params">num_runs=<span class="number">2</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f2</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef3</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f3_woparam</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef3(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f3_wparam</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef4</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f4_woparam</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef4(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f4_wparam</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;add_val_f0 func name: <span class="subst">&#123;add_val_f0.__name__&#125;</span>&quot;</span>)</span><br><span class="line">add_val_f0(np.ones(<span class="number">1000000</span>), <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;add_val_f1 func name: <span class="subst">&#123;add_val_f1.__name__&#125;</span>&quot;</span>)</span><br><span class="line">add_val_f1(np.ones(<span class="number">1000000</span>), <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;add_val_f2 func name: <span class="subst">&#123;add_val_f2.__name__&#125;</span>&quot;</span>)</span><br><span class="line">add_val_f2(np.ones(<span class="number">1000000</span>), <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;add_val_f3_woparam func name: <span class="subst">&#123;add_val_f3_woparam.__name__&#125;</span>&quot;</span>)</span><br><span class="line">add_val_f3_woparam(np.ones(<span class="number">1000000</span>), <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;add_val_f3_wparam func name: <span class="subst">&#123;add_val_f3_wparam.__name__&#125;</span>&quot;</span>)</span><br><span class="line">add_val_f3_wparam(np.ones(<span class="number">1000000</span>), <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;add_val_f4_woparam func name: <span class="subst">&#123;add_val_f4_woparam.__name__&#125;</span>&quot;</span>)</span><br><span class="line">add_val_f4_woparam(np.ones(<span class="number">1000000</span>), <span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;add_val_f4_wparam func name: <span class="subst">&#123;add_val_f4_wparam.__name__&#125;</span>&quot;</span>)</span><br><span class="line">add_val_f4_wparam(np.ones(<span class="number">1000000</span>), <span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">add_val_f0 func name: wrapper</span><br><span class="line">add_val_f0 time cost: 0.257897s</span><br><span class="line">add_val_f1 func name: add_val_f1</span><br><span class="line">add_val_f1 time cost: 0.263955s</span><br><span class="line">add_val_f2 func name: add_val_f2</span><br><span class="line">add_val_f2 time cost: 0.269486s (Avg over 2 runs)</span><br><span class="line">add_val_f3_woparam func name: add_val_f3_woparam</span><br><span class="line">add_val_f3_woparam time cost: 0.257728s</span><br><span class="line">add_val_f3_wparam func name: add_val_f3_wparam</span><br><span class="line">add_val_f3_wparam time cost: 0.283820s (Avg over 2 runs)</span><br><span class="line">add_val_f4_woparam func name: add_val_f4_woparam</span><br><span class="line">add_val_f4_woparam time cost: 0.254313s</span><br><span class="line">add_val_f4_wparam func name: add_val_f4_wparam</span><br><span class="line">add_val_f4_wparam time cost: 0.282968s (Avg over 2 runs)</span><br></pre></td></tr></table></figure></p>
<p>通过类定义装饰器</p>
</details>
<p>装饰器的本质是为函数添加新功能但不更改函数结构，比如在本例中计算时间代价，或是将函数注册到模块中。因此，为了保证函数调用的一致性，装饰器返回的仍是函数对象。被返回的函数一般有两种类型，原始输入函数，或是调用原始输入函数的wrapper函数。需要注意的是，当返回函数为wrapper函数时，由于其是一个新的函数对象，函数相关的属性也就不同。如上例<code>timef0</code>所示，简单返回wrapper函数会导致装饰函数的名字变为新函数的名字，进而破坏了装饰函数在装饰前和装饰后的一致性。为了使得装饰前与装饰后函数属性一致，需要在使用时对wrapper函数加入<code>@functools.wraps(func)</code>装饰器。</p>
<p>在装饰器被调用时，其真正执行的是<code>decorator(func)</code>。如对<code>add_val_f1</code>添加<code>@timef1</code>装饰器时，其在声明时是等同于<code>timef1(add_val_f1)</code>。因此也就可以通过函数嵌套的形式，为装饰器传参。比如上例中的<code>timef2</code>，在声明时相当于<code>timef2(num_runs=2)(add_val_f2)</code>；由于<code>timef2(num_runs=2)</code>的返回值为<code>decorator</code>函数，所以该声明也就等价于<code>decorator(add_val_f2)</code>。在这种函数情况下，<code>timef2</code>只负责传参，而<code>decorator</code>函数才完成类似于<code>timef1</code>的功能。当然笔者更喜欢使用<code>timef2</code>所示的递归的方式，来进行更加灵活的定义和传参。</p>
<p>此外，装饰器是可以嵌套的，具体例子会在下面小节展示。</p>
<h2 id="通过numba.jit加速python-for循环">通过numba.jit加速python
for循环</h2>
<p>上小节提到，在python的for中，即使是相同的代码也需要对字节码进行反复解释，这种执行编译的方式是低效的。在numba中，可以通过添加简单<code>@numba.jit</code>装饰器进行加速，比如可以通过如下代码对上述例子进行加速。</p>
<details>
<summary>
代码：numba.jit加速for循环
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numba</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef</span>(<span class="params">func=<span class="literal">None</span>, num_runs=<span class="number">1</span>, warmup=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;calculate the time cost for the function&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> func:</span><br><span class="line">        <span class="keyword">return</span> functools.partial(timef, num_runs=num_runs, warmup=warmup)</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(warmup):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        startt = time.time()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_runs):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        <span class="keyword">if</span> num_runs == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;(time.time()-startt)/num_runs:<span class="number">0.6</span>f&#125;</span>s (Avg over <span class="subst">&#123;num_runs&#125;</span> runs)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f0</span>(<span class="params">_<span class="built_in">list</span>, val</span>):</span><br><span class="line">    <span class="keyword">return</span> [l+val <span class="keyword">for</span> l <span class="keyword">in</span> _<span class="built_in">list</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f1</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="meta">@numba.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f2</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f2_warmedup</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f3</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f3_warmedup</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, cache=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f4</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, cache=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f4_warmedup</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line">numba.config.NUMBA_DEFAULT_NUM_THREADS=<span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, parallel=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f5</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, parallel=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f5_warmedup</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(ls):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, parallel=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f6</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> numba.prange(<span class="built_in">len</span>(ls)):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, parallel=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_f6_warmedup</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.zeros(<span class="built_in">len</span>(ls))</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> numba.prange(<span class="built_in">len</span>(ls)):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val_numpy</span>(<span class="params">ls, val</span>):</span><br><span class="line">    <span class="keyword">return</span> ls + val</span><br><span class="line"></span><br><span class="line">size=<span class="number">10000000</span></span><br><span class="line">add_val_f0(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f1(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f2(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f2_warmedup(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f3(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f3_warmedup(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f4(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f4_warmedup(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f5(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f5_warmedup(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f6(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_f6_warmedup(np.ones(size), <span class="number">10</span>)</span><br><span class="line">add_val_numpy(np.ones(size), <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>输出: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">add_val_f0 time cost: 2.478387s</span><br><span class="line">add_val_f1 time cost: 4.142665s</span><br><span class="line">add_val_f2 time cost: 0.228293s</span><br><span class="line">add_val_f2_warmedup time cost: 0.037352s (Avg over 2 runs)</span><br><span class="line">add_val_f3 time cost: 0.129881s</span><br><span class="line">add_val_f3_warmedup time cost: 0.036910s (Avg over 2 runs)</span><br><span class="line">add_val_f4 time cost: 0.038818s</span><br><span class="line">add_val_f4_warmedup time cost: 0.036762s (Avg over 2 runs)</span><br><span class="line">add_val_f5 time cost: 0.214643s</span><br><span class="line">add_val_f5_warmedup time cost: 0.017964s (Avg over 2 runs)</span><br><span class="line">add_val_f6 time cost: 0.273015s</span><br><span class="line">add_val_f6_warmedup time cost: 0.010958s (Avg over 2 runs)</span><br><span class="line">add_val_numpy time cost: 0.012424s</span><br></pre></td></tr></table></figure></p>
<p>其中__pychache__中生成对应的缓存文件： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── numba_jit.py</span><br><span class="line">└── __pycache__</span><br><span class="line">    ├── numba_jit.add_val_f4-68.py37m.1.nbc</span><br><span class="line">    ├── numba_jit.add_val_f4-68.py37m.nbi</span><br><span class="line">    ├── numba_jit.add_val_f4_warmedup-76.py37m.1.nbc</span><br><span class="line">    └── numba_jit.add_val_f4_warmedup-76.py37m.nbi</span><br></pre></td></tr></table></figure></p>
</details>
<p>在上诉例子中，可以看到通过简单添加<code>@numba.jit</code>装饰器来对python代码进行加速。通过<code>add_val_fn</code>和<code>add_val_fn_warmedup</code>极大的速度差距可以看到，在<code>@numba.jit</code>中，对于第一次执行还是存在解释编译，因此执行效率相对缓慢。而在第一次解释编译之后，其执行速度几乎达到甚至超过numpy经过优化之后的速度。</p>
<p>在numba.jit中常用到的参数有三个，分别为：nopython，cache和parallel。
*
nopython参数用于控制numba的编译模式，numba有两种编译模式，分别为非python模式和对象模式。当nopython=True时，numba编译模式为非python模式。这种编译模式会产生最高性能的代码，但由于其生成的代码无法访问python
c
api，对于原生python代码的兼容型一般。比如非python模式无法兼任原生的python类作为输入类型，但其可以通过numba.jitclass或是numpy的结构体来解决。
*
cache参数用于控制函数的缓存至磁盘文件，可以通过传递cache=True避免每次调用Python程序时都要进行编译，进而提升第一次执行相对缓慢相对缓慢的情况。如在上例中，add_val_f4通过cache=True缓存下编译过的文件，进而达到与<code>add_val_f4_warmedup</code>相似的速度。需要注意的是当函数缓存文件不存在时，第一次执行该函数将生成缓存文件，而本次执行的速度同样相对缓慢。
*
parallel参数用于控制函数的并行。当parallel=True时，numba对函数内的操作进行并行优化。也可以通过numba.prange进行显示并行循环进而进一步提高执行效率。此外，numba通过<code>numba.config.NUMBA_DEFAULT_NUM_THREADS</code>来指定并行的线程数。</p>
<p>numba.jit足以应付绝大多数的循环，但当一个操作只想针对数组的某一维度进行操作，numba.jit就显得力不从心了。下一小节将讨论如何通过numba中的vectroize和guvectorize生成numpy的通用函数去解决多维数组的扩展问题。</p>
<h2
id="通过numba中的vectroize和guvectorize创建高效的numpy通用函数">通过numba中的vectroize和guvectorize创建高效的numpy通用函数</h2>
<p>在numpy中通用函数ufunc（universal
function），是一种能对数组的每个元素进行操作的函数，一些基本操作如add，dot，max，any等在numpy中都通过c来实现进而达到较好的执行效率。</p>
<p>对于相对较复杂的操作，numpy允许自定义ufunc。但相较于通过c实现的ufunc，通过python自定义的ufunc与原始python函数速度差异不大。而且numpy自定义的ufunc只支持按位操作（elementwise
operation），对于相对较复杂的操作如矩阵乘法这种广义通用函数，numpy的支持并不友好。而numba的vectroize和guvectorize在兼容numpy.ufunc的特性的同时，执行效率高并且支持广义通用函数。</p>
<p>本节示例展示了通过numba中的vectroize和guvectorize分别来加速numpy自定义的ufunc。</p>
<details>
<summary>
代码：numba.vectroize创建高效numpy通用函数 - 按位乘法
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numba</span><br><span class="line"></span><br><span class="line">numba.config.NUMBA_NUM_THREADS=<span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef</span>(<span class="params">func=<span class="literal">None</span>, num_runs=<span class="number">1</span>, warmup=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;calculate the time cost for the function&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> func:</span><br><span class="line">        <span class="keyword">return</span> functools.partial(timef, num_runs=num_runs, warmup=warmup)</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(warmup):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        startt = time.time()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_runs):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        <span class="keyword">if</span> num_runs == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;(time.time()-startt)/num_runs:<span class="number">0.6</span>f&#125;</span>s (Avg over <span class="subst">&#123;num_runs&#125;</span> runs)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_numpy</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    <span class="keyword">return</span> matA*matB</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_python</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    matC = np.empty_like(matA)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(matA.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(matA.shape[<span class="number">1</span>]):</span><br><span class="line">            matC[i,j] = matA[i,j] * matB[i,j]</span><br><span class="line">    <span class="keyword">return</span> matC</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_numba_jit</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    matC = np.empty_like(matA)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(matA.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(matA.shape[<span class="number">1</span>]):</span><br><span class="line">            matC[i,j] = matA[i,j] * matB[i,j]</span><br><span class="line">    <span class="keyword">return</span> matC</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, parallel=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_numba_jit_parallel</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    matC = np.empty_like(matA)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> numba.prange(matA.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> numba.prange(matA.shape[<span class="number">1</span>]):</span><br><span class="line">            matC[i,j] = matA[i,j] * matB[i,j]</span><br><span class="line">    <span class="keyword">return</span> matC</span><br><span class="line"></span><br><span class="line"><span class="meta">@np.vectorize</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_numpy_vectorize</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a*b</span><br><span class="line">dotmul_numpy_vectorize.__name__ = <span class="string">&quot;dotmul_numpy_vectorize&quot;</span></span><br><span class="line">dotmul_numpy_vectorize = timef(num_runs=<span class="number">2</span>, warmup=<span class="number">1</span>)(dotmul_numpy_vectorize)</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.vectorize(<span class="params">nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_numba_vectorize</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a*b</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.vectorize(<span class="params"><span class="string">&#x27;float64(float64, float64)&#x27;</span>, target=<span class="string">&#x27;parallel&#x27;</span>, nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_numba_vectorize_parallel</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a*b</span><br><span class="line"></span><br><span class="line"><span class="meta">@numba.vectorize(<span class="params"><span class="string">&#x27;float64(float64, float64)&#x27;</span>, target=<span class="string">&#x27;cuda&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dotmul_numba_vectorize_cuda</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a*b</span><br><span class="line">dotmul_numba_vectorize_cuda.__name__ = <span class="string">&quot;dotmul_numba_vectorize_cuda&quot;</span></span><br><span class="line">dotmul_numba_vectorize_cuda = timef(num_runs=<span class="number">2</span>, warmup=<span class="number">1</span>)(dotmul_numba_vectorize_cuda)</span><br><span class="line"></span><br><span class="line">size=<span class="number">1000</span></span><br><span class="line">dotmul_python(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">dotmul_numpy(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">dotmul_numba_jit(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">dotmul_numba_jit_parallel(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">dotmul_numpy_vectorize(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">dotmul_numba_vectorize(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">dotmul_numba_vectorize_parallel(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">dotmul_numba_vectorize_cuda(np.ones((size,size)), np.ones((size,size)))</span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dotmul_python time cost: 0.390452s (Avg over 2 runs)</span><br><span class="line">dotmul_numpy time cost: 0.002007s (Avg over 2 runs)</span><br><span class="line">dotmul_numba_jit time cost: 0.002113s (Avg over 2 runs)</span><br><span class="line">dotmul_numba_jit_parallel time cost: 0.001313s (Avg over 2 runs)</span><br><span class="line">dotmul_numpy_vectorize time cost: 0.143894s (Avg over 2 runs)</span><br><span class="line">dotmul_numba_vectorize time cost: 0.001535s (Avg over 2 runs)</span><br><span class="line">dotmul_numba_vectorize_parallel time cost: 0.001899s (Avg over 2 runs)</span><br><span class="line">dotmul_numba_vectorize_cuda time cost: 0.004523s (Avg over 2 runs)</span><br></pre></td></tr></table></figure></p>
</details>
<details>
<summary>
代码：numba.guvectroize创建高效numpy广义通用函数 - 矩阵乘法
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numba</span><br><span class="line"></span><br><span class="line">numba.config.NUMBA_NUM_THREADS=<span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef</span>(<span class="params">func=<span class="literal">None</span>, num_runs=<span class="number">1</span>, warmup=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;calculate the time cost for the function&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> func:</span><br><span class="line">        <span class="keyword">return</span> functools.partial(timef, num_runs=num_runs, warmup=warmup)</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(warmup):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        startt = time.time()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_runs):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        <span class="keyword">if</span> num_runs == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;(time.time()-startt)/num_runs:<span class="number">0.6</span>f&#125;</span>s (Avg over <span class="subst">&#123;num_runs&#125;</span> runs)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_numpy</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    <span class="keyword">return</span> np.matmul(matA, matB)</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_python</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    m, n = matA.shape</span><br><span class="line">    n, p = matB.shape</span><br><span class="line">    matC = np.zeros((m,p))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(p):</span><br><span class="line">            matC[i, j] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                matC[i, j] += matA[i, k] * matB[k, j]</span><br><span class="line">    <span class="keyword">return</span> matC</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_numba_jit</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    m, n = matA.shape</span><br><span class="line">    n, p = matB.shape</span><br><span class="line">    matC = np.zeros((m,p))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(p):</span><br><span class="line">            matC[i, j] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                matC[i, j] += matA[i, k] * matB[k, j]</span><br><span class="line">    <span class="keyword">return</span> matC</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span>, parallel=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_numba_jit_parallel</span>(<span class="params">matA, matB</span>):</span><br><span class="line">    m, n = matA.shape</span><br><span class="line">    n, p = matB.shape</span><br><span class="line">    matC = np.zeros((m,p))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(p):</span><br><span class="line">            matC[i, j] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                matC[i, j] += matA[i, k] * matB[k, j]</span><br><span class="line">    <span class="keyword">return</span> matC</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.guvectorize(<span class="params"><span class="string">&quot;float64[:,:], float64[:,:], float64[:,:]&quot;</span>, <span class="string">&quot;(m,n),(n,p)-&gt;(m,p)&quot;</span>, nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_numba_guvectorize</span>(<span class="params">matA, matB, matC</span>):</span><br><span class="line">    m, n = matA.shape</span><br><span class="line">    n, p = matB.shape</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(p):</span><br><span class="line">            matC[i, j] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                matC[i, j] += matA[i, k] * matB[k, j]</span><br><span class="line"></span><br><span class="line"><span class="meta">@timef(<span class="params">num_runs=<span class="number">2</span>, warmup=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="meta">@numba.guvectorize(<span class="params"><span class="string">&quot;float64[:,:], float64[:,:], float64[:,:]&quot;</span>, <span class="string">&quot;(m,n),(n,p)-&gt;(m,p)&quot;</span>, target=<span class="string">&#x27;parallel&#x27;</span>, nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_numba_guvectorize_parallel</span>(<span class="params">matA, matB, matC</span>):</span><br><span class="line">    m, n = matA.shape</span><br><span class="line">    n, p = matB.shape</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(p):</span><br><span class="line">            matC[i, j] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                matC[i, j] += matA[i, k] * matB[k, j]</span><br><span class="line"></span><br><span class="line"><span class="meta">@numba.guvectorize(<span class="params"><span class="string">&quot;float64[:,:], float64[:,:], float64[:,:]&quot;</span>, <span class="string">&quot;(m,n),(n,p)-&gt;(m,p)&quot;</span>, target=<span class="string">&#x27;cuda&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">matmul_numba_guvectorize_cuda</span>(<span class="params">matA, matB, matC</span>):</span><br><span class="line">    m, n = matA.shape</span><br><span class="line">    n, p = matB.shape</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(p):</span><br><span class="line">            matC[i, j] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                matC[i, j] += matA[i, k] * matB[k, j]</span><br><span class="line">matmul_numba_guvectorize_cuda.__name__ = <span class="string">&quot;matmul_numba_guvectorize_cuda&quot;</span></span><br><span class="line">matmul_numba_guvectorize_cuda = timef(num_runs=<span class="number">2</span>, warmup=<span class="number">1</span>)(matmul_numba_guvectorize_cuda)</span><br><span class="line"></span><br><span class="line">size=<span class="number">1000</span></span><br><span class="line">matmul_python(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">matmul_numpy(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">matmul_numba_jit(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">matmul_numba_jit_parallel(np.ones((size,size)), np.ones((size,size)))</span><br><span class="line">matmul_numba_guvectorize(np.ones((size,size)), np.ones((size,size)), np.zeros((size,size)))</span><br><span class="line">matmul_numba_guvectorize_parallel(np.ones((size,size)), np.ones((size,size)), np.zeros((size,size)))</span><br><span class="line"></span><br><span class="line">size=<span class="number">100</span></span><br><span class="line">matmul_numba_guvectorize_cuda(np.ones((size,size)), np.ones((size,size)), np.zeros((size,size)))</span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">matmul_python time cost: 578.654421s (Avg over 2 runs)</span><br><span class="line">matmul_numpy time cost: 0.011648s (Avg over 2 runs)</span><br><span class="line">matmul_numba_jit time cost: 1.189993s (Avg over 2 runs)</span><br><span class="line">matmul_numba_jit_parallel time cost: 1.129338s (Avg over 2 runs)</span><br><span class="line">matmul_numba_guvectorize time cost: 1.124118s (Avg over 2 runs)</span><br><span class="line">matmul_numba_guvectorize_parallel time cost: 1.129258s (Avg over 2 runs)</span><br><span class="line">matmul_numba_guvectorize_cuda time cost: 0.179321s (Avg over 2 runs)</span><br></pre></td></tr></table></figure></p>
</details>
<p>通过上例可以看到，相较于numpy.vectorize所生成的ufunc，numba.vectorize执行效率更高，甚至超过numpy通过c实现的通用函数的执行速度。而对于numba.guvectorize虽然可以灵活自定义，并且远远超过原始python实现，但相较于numpy优化过的代码仍有差距。</p>
<p>类似于numba.jit，numba.vectorize和numba.guvectorize同样可以通过nopython和cache参数来设置编译模式和缓存文件。与之不同的是，vectorize和guvectorize通过target参数来控制并行计算。当target="cpu"时numba使用单线程，当target="parallel"时numba使用多线程并行。值得一提的是target还可以允许使用nvidia
cuda作为numpy通用函数的计算单元，虽然笔者并不建议。如果读者希望通过cuda加速python代码，可以看笔者的另一篇博客<a
href="https://foreveryounggithub.github.io/zh/2020/06/10/numba_cuda/">Numba:
通过python快速学习cuda编程</a>。</p>
<p>为什么要用ufunc而不是jit？jit更直观，更灵活，甚至更快。主要原因是因为numba生成的numpy.ufunc可以对某些轴进行广播（broadcast），在一些情况下可以会某一些轴进行缩减和累积。这样输入数据的维度就可以更自由。但除此以外，笔者更推荐numba.jit。</p>
<h2 id="numba.pycc提前编译python函数">numba.pycc提前编译python函数</h2>
<p>虽然numba主要的编译方式都是jit，但numba也如cython一样提供提前编译（AoT）的编译方式。本小节对之前numba.jit的例子进行改写，达到了提前编译的效果。</p>
<details>
<summary>
代码：numba.pycc提前编译python函数
</summary>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numba_pycc_module.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numba</span><br><span class="line"><span class="keyword">from</span> numba.pycc <span class="keyword">import</span> CC</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">cc = CC(<span class="string">&#x27;numba_pycc_test_module&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@cc.export(<span class="params"><span class="string">&#x27;add_valf&#x27;</span>, <span class="string">&#x27;f8[:](f8[:], f8)&#x27;</span></span>)</span></span><br><span class="line"><span class="meta">@cc.export(<span class="params"><span class="string">&#x27;add_vali&#x27;</span>, <span class="string">&#x27;i4[:](i4[:], i4)&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_val</span>(<span class="params">ls, val</span>):</span><br><span class="line">    a = np.empty_like(ls)</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> numba.prange(<span class="built_in">len</span>(ls)):</span><br><span class="line">        a[index] = ls[index]+val</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    cc.<span class="built_in">compile</span>()</span><br></pre></td></tr></table></figure>
<p>运行生成.so的二进制文件 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── numba_pycc_module.py</span><br><span class="line">├── numba_pycc_test_module.cpython-37m-x86_64-linux-gnu.so</span><br><span class="line">└── numba_pycc_test.py</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numba_pycc_test.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numba_pycc_test_module</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timef</span>(<span class="params">func=<span class="literal">None</span>, num_runs=<span class="number">1</span>, warmup=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;calculate the time cost for the function&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> func:</span><br><span class="line">        <span class="keyword">return</span> functools.partial(timef, num_runs=num_runs, warmup=warmup)</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(warmup):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        startt = time.time()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_runs):</span><br><span class="line">            result = func(*args, **kw)</span><br><span class="line">        <span class="keyword">if</span> num_runs == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;time.time()-startt:<span class="number">0.6</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;func.__name__&#125;</span> time cost: <span class="subst">&#123;(time.time()-startt)/num_runs:<span class="number">0.6</span>f&#125;</span>s (Avg over <span class="subst">&#123;num_runs&#125;</span> runs)&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line">size=<span class="number">10000000</span></span><br><span class="line">timef(numba_pycc_test_module.add_valf)(np.ones(size), <span class="number">10</span>)</span><br><span class="line">timef(num_runs=<span class="number">2</span>, warmup=<span class="number">1</span>)(numba_pycc_test_module.add_valf)(np.ones(size), <span class="number">10</span>)</span><br><span class="line">timef(numba_pycc_test_module.add_vali)(np.ones(size, dtype=np.int32), <span class="number">10</span>)</span><br><span class="line">timef(num_runs=<span class="number">2</span>, warmup=<span class="number">1</span>)(numba_pycc_test_module.add_vali)(np.ones(size, dtype=np.int32), <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
输出: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">add_valf time cost: 0.027234s</span><br><span class="line">add_valf time cost: 0.029468s (Avg over 2 runs)</span><br><span class="line">add_vali time cost: 0.019918s</span><br><span class="line">add_vali time cost: 0.018991s (Avg over 2 runs)</span><br></pre></td></tr></table></figure>
</details>
<p>通过上例可以看到，通过numba.pycc可以提前编译生成的python函数为机械码。被编译的模块在运行时没有编译开销，也不依赖于Numba库。numba.pycc还可以将编译步骤集成到setuptools等脚本中。虽然numba.pycc使用起来灵活方便，但也有其局限性。如摆脱对numba依赖的同时也无法使用numba的一下特性，比如并行计算。而且numba.pycc编译仅允许使用常规的numba.jit函数，不能使用ufuncs。</p>
<p>至此，笔者对于通过numba加速python代码的介绍就结束了。在笔者使用numba时，虽然有些许的局限性，但其灵活简单的语法，对numpy数组较为完备的支持，保持python原有函数结构上对其极大的提速令笔者非常满意。此外，本文对一些其他笔者不太常用的功能并没有提及，如numba中的cfunc，jit中的nogil等。而且numba在仍在高效的迭代开发，一些实验性的功能如jit_module等都非常有趣。希望读者通过本文对numba有初步的了解，进而运用到自己的项目中。如有需要，多多查看官方手册。祝好，共勉。</p>
<h2 id="参考">参考</h2>
<p>在撰写本文时，大量的参考了官方文档和其他博客，收益良多。观点表述如有雷同，可视为出自原作者。相关参考链接如下：
* <a href="http://numba.pydata.org/numba-doc/latest/">numba document</a>
* <a
href="https://zhuanlan.zhihu.com/c_1111226743037448192">python高性能编程与实战案例代码总结</a>
* <a href="https://zhuanlan.zhihu.com/p/27152060">numba 的基本应用</a> *
<a
href="https://blog.reverberate.org/2012/12/hello-jit-world-joy-of-simple-jits.html">Hello,
JIT World: The Joy of Simple JITs</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numba</tag>
      </tags>
  </entry>
  <entry>
    <title>pybind:为cpp/cuda代码提供python接口</title>
    <url>/zh/2020/09/20/zh/python_cpp_extension/</url>
    <content><![CDATA[<p>python调用C++/CUDA有不少的方法，如boost.python, cython,
pybind11等。其中，pybind11是一个轻量级的仅标头的库。由于pybind11的易用性，pybind11被很多库用于于创建现有C++/CUDA代码的Python绑定，比如pytorch，tvm等。此外，由于Python的缓冲区协议可以公开自定义数据类型的内部存储，python的矩阵类型（如numpy.ndarry,torch.Tensor）可以快速转化到C++中对应矩阵类型（如Eigen，cv::Mat，vector等），不须额外的复制操作。本篇文章将通过一个数列求和的例子来讲解如何使用pybind11来将C++/CUDA代码进行Python绑定。</p>
<p>在通过C++和CUDA实现数列求和，在将其绑定为python函数，并在python中调用对应函数，验证结果。</p>
<span id="more"></span>
<h2 id="基本环境">基本环境</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GCC: 7.5</span><br><span class="line">CUDA: 10.2</span><br><span class="line">CUDNN: 7.6.5</span><br><span class="line">Python: 3.7</span><br><span class="line">pybind11: 2.5</span><br></pre></td></tr></table></figure>
<h2 id="hello-world-for-pybind11">"hello, world!" for pybind11</h2>
<p>不同于pybind11官网推荐的通过CMake编译的编译方式，本文将采用pytorch中pybind11的编译方式，即在setup创建python包时编译项目中C++和CUDA代码。</p>
<details>
<summary>
代码："hello, world!"
</summary>
<p>工程目录及编译： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.../pybind$ tree</span><br><span class="line">.</span><br><span class="line">└── hello_world</span><br><span class="line">    ├── cpp_extension.py</span><br><span class="line">    ├── hello_world.cpp</span><br><span class="line">    └── setup_hello.py</span><br><span class="line">.../pybind$ python setup_hello.py clean -a install</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p><code>hello_world.cpp</code>: <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> py = pybind11;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HelloRobot</span> &#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">HelloRobot</span>(<span class="type">const</span> std::string &amp; robot_name) : <span class="built_in">robot_name_</span>(robot_name) &#123;&#125;;</span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">hello</span><span class="params">(std::string guest_name)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(guest_name == <span class="string">&quot;&quot;</span>) &#123;</span><br><span class="line">                guest_name = <span class="string">&quot;World&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Hello, &quot;</span> + guest_name + <span class="string">&quot;! I&#x27;m &quot;</span> + robot_name_ + <span class="string">&quot;.\n&quot;</span>;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="function">std::string <span class="title">get_robot_name</span><span class="params">()</span> </span>&#123;<span class="keyword">return</span> robot_name_;&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        std::string robot_name_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(hello_world, m) &#123;</span><br><span class="line">    m.<span class="built_in">doc</span>() = <span class="string">&quot;pybind11 hello world&quot;</span>;</span><br><span class="line"></span><br><span class="line">    py::<span class="built_in">class_</span>&lt;HelloRobot&gt;(m, <span class="string">&quot;HelloRobot&quot;</span>)</span><br><span class="line">        .<span class="built_in">def</span>(py::<span class="built_in">init</span>&lt;<span class="type">const</span> std::string &amp;&gt;())</span><br><span class="line">        .<span class="built_in">def</span>(<span class="string">&quot;hello&quot;</span>, &amp;HelloRobot::hello, <span class="string">&quot;Provide your name...&quot;</span>, py::<span class="built_in">arg</span>(<span class="string">&quot;guest_name&quot;</span>)=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        .<span class="built_in">def_property_readonly</span>(<span class="string">&quot;robot_name&quot;</span>, &amp;HelloRobot::get_robot_name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>setup_hello.py</code>: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> cpp_extension <span class="keyword">import</span> BuildExtension, CUDAExtension</span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;hello&#x27;</span>,</span><br><span class="line">    version=<span class="string">&#x27;0.1&#x27;</span>,</span><br><span class="line">    description=<span class="string">&#x27;pybind11 hello world&#x27;</span>,</span><br><span class="line">    python_requires=<span class="string">&#x27;&gt;=3.7&#x27;</span>,</span><br><span class="line">    setup_requires=[<span class="string">&#x27;pybind11&gt;=2.5.0&#x27;</span>],</span><br><span class="line">    ext_modules=[CUDAExtension(<span class="string">&#x27;hello_world&#x27;</span>,</span><br><span class="line">        [<span class="string">&quot;hello_world.cpp&quot;</span>],</span><br><span class="line">        extra_compile_args=&#123;</span><br><span class="line">            <span class="string">&#x27;cxx&#x27;</span>: [<span class="string">&#x27;-std=c++14&#x27;</span>, <span class="string">&#x27;-O2&#x27;</span>, <span class="string">&#x27;-Wall&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;nvcc&#x27;</span>: [</span><br><span class="line">                <span class="string">&#x27;-std=c++14&#x27;</span>, <span class="string">&#x27;--expt-extended-lambda&#x27;</span>, <span class="string">&#x27;--use_fast_math&#x27;</span>, <span class="string">&#x27;-Xcompiler&#x27;</span>, <span class="string">&#x27;-Wall&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;-gencode=arch=compute_60,code=sm_60&#x27;</span>, <span class="string">&#x27;-gencode=arch=compute_61,code=sm_61&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;-gencode=arch=compute_70,code=sm_70&#x27;</span>, <span class="string">&#x27;-gencode=arch=compute_72,code=sm_72&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;-gencode=arch=compute_75,code=sm_75&#x27;</span>, <span class="string">&#x27;-gencode=arch=compute_75,code=compute_75&#x27;</span></span><br><span class="line">            ],</span><br><span class="line">        &#125;,</span><br><span class="line">        include_dirs = [],</span><br><span class="line">        library_dirs = [<span class="string">&#x27;/usr/local/lib&#x27;</span>, <span class="string">&#x27;/usr/local/lib64/&#x27;</span>],</span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">    cmdclass=&#123;<span class="string">&#x27;build_ext&#x27;</span>: BuildExtension.with_options(no_python_abi_suffix=<span class="literal">True</span>, use_ninja=<span class="literal">False</span>)&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>简单测试： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">.../pybind/hello_world$ python</span><br><span class="line">Python <span class="number">3.7</span><span class="number">.7</span> (default, May  <span class="number">7</span> <span class="number">2020</span>, <span class="number">21</span>:<span class="number">25</span>:<span class="number">33</span>) </span><br><span class="line">[GCC <span class="number">7.3</span><span class="number">.0</span>] :: Anaconda, Inc. on linux</span><br><span class="line"><span class="type">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">ModuleNotFoundError: No module named <span class="string">&#x27;hello&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> hello_world</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello_world.HelloRobot</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;hello_world.HelloRobot&#x27;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>robot = hello_world.HelloRobot(<span class="string">&quot;Eva&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>robot.robot_name</span><br><span class="line"><span class="string">&#x27;Eva&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>robot.hello()</span><br><span class="line">Hello, World! I<span class="string">&#x27;m Eva.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; robot.hello(&quot;Young&quot;)</span></span><br><span class="line"><span class="string">Hello, Young! I&#x27;</span>m Eva.</span><br></pre></td></tr></table></figure></p>
<p>通过pybind11生成模块的相关文档： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> hello_world</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">help</span>(hello_world)</span><br><span class="line"></span><br><span class="line">Help on module hello_world:</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">    hello_world - pybind11 hello world</span><br><span class="line"></span><br><span class="line">CLASSES</span><br><span class="line">    pybind11_builtins.pybind11_object(builtins.<span class="built_in">object</span>)</span><br><span class="line">        HelloRobot</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">HelloRobot</span>(pybind11_builtins.pybind11_object)</span><br><span class="line">     |  Method resolution order:</span><br><span class="line">     |      HelloRobot</span><br><span class="line">     |      pybind11_builtins.pybind11_object</span><br><span class="line">     |      builtins.<span class="built_in">object</span></span><br><span class="line">     |  </span><br><span class="line">     |  Methods defined here:</span><br><span class="line">     |  </span><br><span class="line">     |  __init__(...)</span><br><span class="line">     |      __init__(self: hello_world.HelloRobot, arg0: <span class="built_in">str</span>) -&gt; <span class="literal">None</span></span><br><span class="line">     |  </span><br><span class="line">     |  hello(...)</span><br><span class="line">     |      hello(self: hello_world.HelloRobot, guest_name: <span class="built_in">str</span> = <span class="string">&#x27;&#x27;</span>) -&gt; <span class="literal">None</span></span><br><span class="line">     |      </span><br><span class="line">     |      Provide your name...</span><br><span class="line">     |  </span><br><span class="line">     |  ----------------------------------------------------------------------</span><br><span class="line">     |  Data descriptors defined here:</span><br><span class="line">     |  </span><br><span class="line">     |  robot_name</span><br><span class="line">     |  </span><br><span class="line">     |  ----------------------------------------------------------------------</span><br><span class="line">     |  Static methods inherited <span class="keyword">from</span> pybind11_builtins.pybind11_object:</span><br><span class="line">     |  </span><br><span class="line">     |  __new__(*args, **kwargs) <span class="keyword">from</span> pybind11_builtins.pybind11_type</span><br><span class="line">     |      Create <span class="keyword">and</span> <span class="keyword">return</span> a new <span class="built_in">object</span>.  See <span class="built_in">help</span>(<span class="built_in">type</span>) <span class="keyword">for</span> accurate signature.</span><br></pre></td></tr></table></figure></p>
</details>
<h2 id="数列求和">数列求和</h2>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>cuda</tag>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title>通过NPP加速TensorRT部署时图片数据预处理</title>
    <url>/zh/2020/06/17/zh/trt_preproc_npp/</url>
    <content><![CDATA[<p>TensorRT(TRT)是NVIDIA推出的一个高性能的深度学习推理框架，可以让深度学习模型在NVIDIA
GPU上实现低延迟，高吞吐量的部署。主流框架的模型可以通过转换为TensorRT在NVIDIA
GPU进而达到极大地提速。然而，由于TensorRT并不支持常见的图片数据类型uint8，这使得往往需要在cpu上进行图片数据预处理，转换为其所支持的float并传入到gpu模型输入。当图片较大时，数据在cpu上的处理和传递时间较慢。本文将介绍如何通过cuda中的npp库来加速这一过程。</p>
<span id="more"></span>
<h2 id="基本环境">基本环境</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYS: Ubuntu 18.04</span><br><span class="line">GPU: T4</span><br><span class="line">GCC: 7.5</span><br><span class="line">CMake: 3.16.6</span><br><span class="line">CUDA: 10.2</span><br><span class="line">CUDNN: 7.6.5</span><br><span class="line">TensorRT: 7.0</span><br><span class="line">OpenCV: 4.3.0/3.4.10</span><br></pre></td></tr></table></figure>
<p>模型是由ssds.pytorch训练的Yolov3目标检测器，已转换为TRT模型。其输入大小为1x3x736x1280，特征提取器为ResNet18，计算精度为int8。</p>
<p>需要注意，当将模型转换为TRT模型时，TRT会根据gpu框架和性能来来选择不同的核函数及其参数，进而最大程度优化推理速度。因此TRT在执行时，必须使用统一gpu框架所生成的TRT模型，否则将无法推断。并且即使是统一框架不同型号的gpu所生成的TRT模型，其推理速度也会有些许削弱。比如虽然2080ti和t4同属7.5计算框架，在T4上推断，由2080ti所生成的TRT模型要比由T4生成的模型推断速度慢3~10%。</p>
<h2 id="cpu图片数据预处理">CPU图片数据预处理</h2>
<p>在一些深度学习框架中，在其推断时可以指定推断时所接受的数据类型，并将数据预处理的步骤在计算图中定义。如在tensorflow将权重转化为推断模型(frozen
graph)时，可以通过<code>tf.placeholder(dtype=tf.uint8, shape=input_shape, name='image_tensor')</code>来指定推理时模型接受的数据类型。这种改变在推理时模型的操作在TensorRT上似乎不那么行得通。虽然TensorRT支持多种数据类型，并且输入输出接口的数据类型可由转换的onnx或uff文件决定，但当输入输出的数据类型改为除float32以外的其他类型时，常常无法成功转换为TRT推理模型。</p>
<p>TensorRT中这种输入输出类型的限制，对于计算机视觉的模型显得更加不友好。计算机视觉常处理的图像或视频在计算机中常存储为0～255的uint8数据，这种类型本身就不被TensorRT所支持，须将图片先转为float数据再输入到TensorRT。而在一些任务中，其输入模型的图片或视频片段分辨率较大，如4k或8k，uint8和float从cpu内存传输到gpu显存的速度差别就比较大。这些原因导致了在计算机视觉模型部署时，图片数据预处理和传输有时候成为了模型部署的瓶颈。</p>
<p>大多数github上的TRT项目在进行推断中的图片数据预处理常采用TensorRT<a
href="https://github.com/NVIDIA/TensorRT/blob/572d54f91791448c015e74a4f1d6923b77b79795/samples/opensource/sampleSSD/sampleSSD.cpp#L276-L309">官方示例</a>中给出了一种在CPU图片数据预处理。笔者个人喜欢用OpenCV自带函数进行操作，这两种图片数据预处理的示例代码如下。</p>
<details>
<summary>
代码：CPU图片数据预处理
</summary>
<p>TensorRT官方示例图片数据预处理代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">SampleUffSSD::processInput</span><span class="params">(<span class="type">const</span> samplesCommon::BufferManager&amp; buffers)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> inputC = mInputDims.d[<span class="number">0</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> inputH = mInputDims.d[<span class="number">1</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> inputW = mInputDims.d[<span class="number">2</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> batchSize = mParams.batchSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Available images</span></span><br><span class="line">    std::vector&lt;std::string&gt; imageList = &#123;<span class="string">&quot;dog.ppm&quot;</span>, <span class="string">&quot;bus.ppm&quot;</span>&#125;;</span><br><span class="line">    mPPMs.<span class="built_in">resize</span>(batchSize);</span><br><span class="line">    <span class="built_in">assert</span>(mPPMs.<span class="built_in">size</span>() &lt;= imageList.<span class="built_in">size</span>());</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; batchSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">readPPMFile</span>(<span class="built_in">locateFile</span>(imageList[i], mParams.dataDirs), mPPMs[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span>* hostDataBuffer = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(mParams.inputTensorNames[<span class="number">0</span>]));</span><br><span class="line">    <span class="comment">// Host memory for input buffer</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>, volImg = inputC * inputH * inputW; i &lt; mParams.batchSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; inputC; ++c)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// The color image to input should be in BGR order</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">unsigned</span> j = <span class="number">0</span>, volChl = inputH * inputW; j &lt; volChl; ++j)</span><br><span class="line">            &#123;</span><br><span class="line">                hostDataBuffer[i * volImg + c * volChl + j]</span><br><span class="line">                    = (<span class="number">2.0</span> / <span class="number">255.0</span>) * <span class="built_in">float</span>(mPPMs[i].buffer[j * inputC + c]) - <span class="number">1.0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenCV图片数据预处理代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">imageToTensor</span><span class="params">(<span class="type">const</span> std::vector&lt;cv::Mat&gt; &amp; images, <span class="type">float</span> * tensor, <span class="type">const</span> <span class="type">int</span> batch_size, <span class="type">const</span> <span class="type">float</span> alpha, <span class="type">const</span> <span class="type">float</span> beta)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> height = images[<span class="number">0</span>].rows;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> width = images[<span class="number">0</span>].cols;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> channels = images[<span class="number">0</span>].<span class="built_in">channels</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stridesCv[<span class="number">3</span>] = &#123; width * channels, channels, <span class="number">1</span> &#125;;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> strides[<span class="number">4</span>] = &#123; height * width * channels, height * width, width, <span class="number">1</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> omp parallel for num_threads(c_numOmpThread) schedule(static, 1)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> b = <span class="number">0</span>; b &lt; batch_size; b++)</span><br><span class="line">    &#123;</span><br><span class="line">        cv::Mat image_f;</span><br><span class="line">        images[b].<span class="built_in">convertTo</span>(image_f, CV_32F, alpha, beta);</span><br><span class="line">        std::vector&lt;cv::Mat&gt; split_channels = &#123;</span><br><span class="line">                cv::<span class="built_in">Mat</span>(images[b].<span class="built_in">size</span>(),CV_32FC1,tensor + b * strides[<span class="number">0</span>]),</span><br><span class="line">                cv::<span class="built_in">Mat</span>(images[b].<span class="built_in">size</span>(),CV_32FC1,tensor + b * strides[<span class="number">0</span>] + strides[<span class="number">1</span>]),</span><br><span class="line">                cv::<span class="built_in">Mat</span>(images[b].<span class="built_in">size</span>(),CV_32FC1,tensor + b * strides[<span class="number">0</span>] + <span class="number">2</span>*strides[<span class="number">1</span>]),</span><br><span class="line">        &#125;;</span><br><span class="line">        cv::<span class="built_in">split</span>(image_f, split_channels);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batch_size * height * width * channels;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenCV图片数据预处理运算速度(ms)</p>
<table>
<colgroup>
<col style="width: 38%" />
<col style="width: 17%" />
<col style="width: 13%" />
<col style="width: 15%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">GPU(Precision)</th>
<th style="text-align: center;">Image2Float</th>
<th style="text-align: center;">Copy2GPU</th>
<th style="text-align: center;">Inference</th>
<th style="text-align: center;">GPU2CPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">t4(int8)</td>
<td style="text-align: center;">2.53026</td>
<td style="text-align: center;">0.935451</td>
<td style="text-align: center;">2.56143</td>
<td style="text-align: center;">0.0210528</td>
</tr>
</tbody>
</table>
</details>
<p>如上例代码所示，在CPU图片数据预处理中，首先将数据转化为float类型并做归一化，然后将数据排列从NHWC转化为NCHW，最后将float型nchw图片数据传递给到TRT模型预留的gpu显存。可以看到，对于该模型图像预处理和传输的速度反而大于模型推断速度。这种cpu图片预处理方式无法高效使用gpu的性能，使得整个模型部署效率较低。</p>
<h2 id="gpu-npp图片数据预处理">GPU-NPP图片数据预处理</h2>
<p>上面提到，cpu图片数据预处理效率较低由两方面原因导致：其一，cpu将图像从uint8转化为float32的效率较低；其二，相较于uint8，float32从cpu传输到gpu数据量大四倍，传输效率较慢。所以比较朴素的提速想法就是将uint8数据传输到gpu，并由gpu完成从uint8转化为float32的转化。NPP就可以方便快速的实现如上过程。</p>
<p>NPP是nvidia推出的用于gpu加速2D图像和信号处理的cuda库，其本身就内嵌于cuda库中。其分为多个部分，可以在gpu上高效的进行数据类型转换，颜色变化，几何变化等功能。本例中采用其中的NPPC，NPPIDEI和NPPIAL部分来进行图片数据预处理中的uint8到float32的数据类型转化，NHWC到NCHW的通道变化，以及归一化操作。其具体代码如下。</p>
<details>
<summary>
代码：GPU-NPP图片数据预处理
</summary>
<p>NPP图片数据预处理代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">imageToTensorGPUFloat</span><span class="params">(<span class="type">const</span> std::vector&lt;cv::Mat&gt; &amp; images, <span class="type">void</span> * gpu_images, <span class="type">void</span> * tensor, <span class="type">const</span> <span class="type">int</span> batch_size, <span class="type">const</span> <span class="type">float</span> alpha)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> height = images[<span class="number">0</span>].rows;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> width  = images[<span class="number">0</span>].cols;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> channels = images[<span class="number">0</span>].<span class="built_in">channels</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stride = height * width * channels;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stride_s = width * channels;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> dstOrder[<span class="number">3</span>] = &#123;<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>&#125;;</span><br><span class="line">    Npp32f scale[<span class="number">3</span>] = &#123;alpha, alpha, alpha&#125;;</span><br><span class="line">    NppiSize dstSize = &#123;width, height&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> omp parallel for num_threads(c_numOmpThread) schedule(static, 1)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> b = <span class="number">0</span>; b &lt; batch_size; b++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cudaMemcpy</span>((Npp8u*)gpu_images + b * stride, images[b].data, stride, cudaMemcpyHostToDevice);</span><br><span class="line">        <span class="built_in">nppiSwapChannels_8u_C3IR</span>((Npp8u*)gpu_images + b * stride, stride_s, dstSize, dstOrder);</span><br><span class="line">        <span class="built_in">nppiConvert_8u32f_C3R</span>((Npp8u*)gpu_images + b * stride, stride_s, (Npp32f*)tensor, stride_s*<span class="built_in">sizeof</span>(<span class="type">float</span>), dstSize);</span><br><span class="line">        <span class="built_in">nppiMulC_32f_C3IR</span>(scale, (Npp32f*)tensor, stride_s*<span class="built_in">sizeof</span>(<span class="type">float</span>), dstSize);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batch_size * stride;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>NPP图片数据预处理代码（无通道变化和归一化） <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">imageToTensorGPUFloat</span><span class="params">(<span class="type">const</span> std::vector&lt;cv::Mat&gt; &amp; images, <span class="type">void</span> * gpu_images, <span class="type">void</span> * tensor, <span class="type">const</span> <span class="type">int</span> batch_size)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> height = images[<span class="number">0</span>].rows;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> width  = images[<span class="number">0</span>].cols;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> channels = images[<span class="number">0</span>].<span class="built_in">channels</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stride = height * width * channels;</span><br><span class="line">    NppiSize dstSize = &#123;width, height&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> omp parallel for num_threads(c_numOmpThread) schedule(static, 1)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> b = <span class="number">0</span>; b &lt; batch_size; b++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cudaMemcpy</span>((Npp8u*)gpu_images + b * stride, images[b].data, stride, cudaMemcpyHostToDevice);</span><br><span class="line">        <span class="built_in">nppiConvert_8u32f_C3R</span>((Npp8u*)gpu_images + b * stride, width * channels, (Npp32f*)tensor, width * channels*<span class="built_in">sizeof</span>(<span class="type">float</span>), dstSize);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batch_size * stride;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>NPP图片数据预处理（无通道变化和归一化）运算速度(ms)</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">GPU(Precision)</th>
<th style="text-align: center;">Image2GPU2Float</th>
<th style="text-align: center;">Inference</th>
<th style="text-align: center;">GPU2CPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">t4(int8)</td>
<td style="text-align: center;">0.532469</td>
<td style="text-align: center;">3.07869</td>
<td style="text-align: center;">0.0208867</td>
</tr>
</tbody>
</table>
</details>
<p>如上例代码所示，在GPU图片数据预处理中，首先将uint8数据传输到gpu显存中，然后将数据排列从NHWC转化为NCHW，最后转化为float类型并做归一化，归一化后的数据直接存储在TRT模型预留的gpu显存中。由于按位运算(elementwise)和通道转换(channel
permute)在TRT模型中执行效率较高，可将预处理中的归一化和通道转换移到模型内计算。可以看到，相较于cpu的图像预处理，gpu图像预处理的时间从3.5ms降到0.5ms，整个模型总运行时间从6ms降到3.5ms，每秒帧处理量（fps）从166帧提升到了285帧，整体达到了1.7倍的提速。</p>
<p>需要注意的是，由于TRT模型转化时间较长，本文示例只测试batch为1时的执行速度。如果在部署时遇到batch较大而导致gpu图片预处理速度较慢，由于cuda代码执行和传输特性，可考虑整批图像一起从cpu内存拷贝到gpu并进行uint8到float32的转化，进而提高大batch情况下的GPU图片数据预处理处理速度。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a
href="https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/infer/FoundationalTypes/DataType.html">tensorrt
document</a></li>
<li><a
href="https://developer.nvidia.com/cuda-gpus#compute">gpu计算框架</a></li>
<li><a
href="https://github.com/ShuangXieIrene/ssds.pytorch">ssds.pytorch</a></li>
</ul>
<p>如果有TensorRT的项目，不妨来试试通过本文提到的GPU图片数据预处理的方法来提速模型推断流程的速度吧！</p>
]]></content>
      <categories>
        <category>model inference</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>cpp</tag>
        <tag>tensorrt</tag>
      </tags>
  </entry>
  <entry>
    <title>基本图像局部区域（Patch）的描述符（local descriptor）学习策略</title>
    <url>/zh/2022/02/27/zh/patch_based_local_descriptor/</url>
    <content><![CDATA[<p>一些计算机视觉任务会依赖图像的几何关系，比如相机定位，三维重建等等。一种方法用于求解图像的几何关系是通过图像局部特征的相关匹配来求解。图像的局部特征则是从<strong>图像局部</strong>区域中抽取的<strong>特征</strong>，包括边缘、角点、线、曲线和特别属性的区域等。一般来说，图像的局部特征包含两个部分，局部特征点的位置，局部特征的描述符。在一方面上，描述符可分为基于人工的特征符和基于学习的特征符。</p>
<p>文本将关注于在特征点已知的情况下，如何通过学习去生成描述符去描述局部区域(Patch)的。相较于网络架构，本文主要关注于不同论文的数据处理和学习策略。</p>
<span id="more"></span>
<h2 id="数据和任务">数据和任务</h2>
<p>基本Patch的描述符（local descriptor）即给定Patch生成local
descriptor。对于神经网络来说，即意味着网络的输入是图像局部区域(Patch)，网络的输出是该Patch的特征。</p>
<p>其中图像局部区域(Patch)是基于图像的特征点所提取的的。如下图所示，下面五个图像来自于同一场景，图上的圆圈的中心即是特征点，而圆圈所选择的区域即是Patch。</p>
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/images_hard.jpg" class="" title="HPatch原始和特征点">
<p>需要注意的是，由于五个图像来自于同一场景，图像中的特征点也一一匹配。如下图所示，下图的每一列都是从匹配的特征点所提取的局部区域，而每一行则代表了从每幅图像所提取的全部Patch。</p>
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/patches_hard.jpg" class="" title="HPatch提取的局部区域">
<p>理想的描述符（local
descriptor）是使得匹配的特征点的描述符一致或距离相近，不匹配的特征点的描述符距离较远。对应于上图，即每一列样本之间的描述符应距离相近，而每一行的样本之间的描述符应距离较远。</p>
<p>在数学上，假设有一特征点<span
class="math inline">\(A\)</span>，其描述符标为<span
class="math inline">\(\textbf{a}\)</span>，称之参考样本或锚点（anchor）。与之匹配的特征点<span
class="math inline">\(P\)</span>可被称为正样本（positive
sample），其描述符标为<span
class="math inline">\(\textbf{p}\)</span>。与之匹配的特征点<span
class="math inline">\(N\)</span>可被称为负样本（negative
sample），其描述符标为<span
class="math inline">\(\textbf{n}\)</span>。理想情况下，参考样本与正样本之间的距离应远小于参考样本与负样本之间的距离，即<span
class="math inline">\(0 \simeq dist(\textbf{a}, \textbf{p}) \ll
dist(\textbf{a}, \textbf{n})\)</span>。</p>
<h2 id="训练流程">训练流程</h2>
<p>对于基本Patch的描述符（local
descriptor），一个常见的训练流程如下图所示。</p>
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/general_pipeline.jpg" class="" title="Pipeline">
<h3 id="数据采样">数据采样</h3>
<p>具体而言，随机选取<span
class="math inline">\(n\)</span>对匹配的patches组成最终的training
batch，所以最终的training batch为<span class="math inline">\(\textbf{x}
= (\textbf{A}_i, \textbf{P}_{i})_{i=1,...,n}\)</span>。其中<span
class="math inline">\((\textbf{A}_i, \textbf{P}_{i})\)</span>
表示对应的一对匹配的patch对。</p>
<h3 id="描述子和距离矩阵">描述子和距离矩阵</h3>
<p>通过神经网络，可以生成样本<span class="math inline">\((\textbf{A}_i,
\textbf{P}_{i})\)</span>所对应的描述子<span
class="math inline">\((\textbf{a}_i,
\textbf{p}_{i})\)</span>。针对于同一batch中的参考样本和正样本俩俩组合计算距离，可得到上图右侧所示的距离矩阵。当组合的参考样本和正样本匹配时，则该距离为正样本距离，不匹配时，则该距离为负样本样本距离。</p>
<p>对于描述子和距离矩阵，可采用不同的损失函数，进而学习网络。</p>
<h2 id="学习策略">学习策略</h2>
<h3
id="l2net-l2-net-deep-learning-of-discriminative-patch-descriptor-in-euclidean-space">L2Net
| <a
href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Tian_L2-Net_Deep_Learning_CVPR_2017_paper.pdf">L2-Net:
Deep Learning of Discriminative Patch Descriptor in Euclidean
Space</a></h3>
<p>L2Net是相对早期的Patch-Based基于深度学习的描述符。其损失函数基本已不再使用，但其模型直至现在仍被广泛使用。</p>
<p>L2Net损失函数主要分为三个部分： - Error term for descriptor
similarity：利用相对距离区分匹配上和未匹配上的 patch
pairs，即在距离矩阵的行和列上求softmax； - Error term for descriptor
compactness：考虑最后输出特征向量的
compactness，也就是特征向量的各个维度尽可能不相关。即在相关矩阵上加penalty；
- Error term for intermediate feature maps：学习过程中间的 feature maps
进行额外的监督，可以得到更好的性能。即求每个中间层的距离矩阵，并在该距离矩阵的行和列上求softmax。</p>
<p>L2Net模型如下图所示。L2Net采用单路全卷积框架，图中3x3
Conv代表Conv+BN+Relu，8×8
Conv代表Conv+BN，在第三层和第五层的卷积层步长为2用于下采样。LRN(Local
Response Normalization
layer)用于归一化输出，等价于L2Norm。需要注意的是，由于区域图像变化较大，为了消除光照等其他因素的影响，一般也会在模型初始加InstanceNorm。</p>
<pre class="mermaid">
flowchart LR
Input[Patch] --&gt; B(3x3 Conv 32):::Conv
B --&gt; C(3x3 Conv 32):::Conv
C --&gt; D(3x3 Conv 64&#x2F;2):::ConvDown
D --&gt; E(3x3 Conv 64):::Conv
E --&gt; F(3x3 Conv 128&#x2F;2):::ConvDown
F --&gt; G(3x3 Conv 128):::Conv
G --&gt; H(8x8 Conv 128):::ConvBN
H --&gt; J(LRN):::LRN
J --&gt; Descriptor(Descriptor)

classDef Conv fill:#cfc;
classDef ConvDown fill:#cff;
classDef ConvBN fill:#ffc;
classDef LRN fill:#fcc;
</pre>
<p>该网络简单直接，特征提取速度在ms级，在低端gpu上基本在1ms左右。</p>
<h3
id="hardnet-working-hard-to-know-your-neighbors-margins-local-descriptor-learning-loss">HardNet
| <a href="https://arxiv.org/abs/1705.10872">Working hard to know your
neighbor's margins: Local descriptor learning loss</a></h3>
<p>HardNet的训练流程如下图所示。</p>
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/hardnet_pipeline.jpg" class="" title="HardNet_Pipeline">
<p>简单而讲，HardNet采用了度量学习中的triplet loss去最大化training
batch中正负样本之间的距离。</p>
<p>具体而言，当距离矩阵已知时，对于匹配的Patch对，可以找到： - <span
class="math inline">\(\textbf{a}_i\)</span>: anchor 描述符 - <span
class="math inline">\(\textbf{p}_{i}\)</span> : positive 描述符 - <span
class="math inline">\(\textbf{p}_{j_{ \min }}\)</span>: 表示距离<span
class="math inline">\(\textbf{a}_i\)</span>最近的非匹配描述符，其中
<span class="math inline">\(j_{\min} = \arg\min_{j=1 . . n , j \neq i }
d \left( a _ { i } , p _ { j }\right)\)</span> ，在上图中对应 <span
class="math inline">\(\textbf{p}_{4}\)</span> - <span
class="math inline">\(\textbf{a}_{k_{ \min }}\)</span>: 表示距离 <span
class="math inline">\(\textbf{p}_{i}\)</span>最近的非匹配描述符，其中
<span class="math inline">\(k_{\min} = \arg\min_{k=1 . . n , k \neq i }
d \left( a _ { k } , p _ { i }\right)\)</span>，在上图中对应 <span
class="math inline">\(\textbf{a}_2\)</span></p>
<p>这样对于每个匹配的 patch pair 在都可以生成一个四元组 <span
class="math inline">\((\textbf{a}_i, \textbf{p}_{i}, \textbf{p}_{j_{
\min }}, \textbf{a}_{k_{ \min }})\)</span>。而在四元组的距离包括:</p>
<ul>
<li><span class="math inline">\(d \left( \textbf{a}_i , \textbf{p}_{i}
\right)\)</span>: anchor-positive 距离</li>
<li><span class="math inline">\(d \left( \textbf{a}_i , \textbf{p}_{j_{
\min }} \right)\)</span>: anchor-negative 距离</li>
<li><span class="math inline">\(d \left( \textbf{a}_{k_{ \min }} ,
\textbf{p}_{i} \right)\)</span>: anchor-negative 距离</li>
</ul>
<p>由于最后的目标是最大化training
batch中正负样本之间的距离。所以将选取最难的样本进行训练，对应于anchor-negative
距离中，即意味着距离最小的样本。因此，最终的损失函数为：</p>
<p><span class="math display">\[L = \frac { 1 } { n } \sum _ { i = 1 , n
} \max \left( 0,1 + d \left( \textbf{a}_i , \textbf{p}_{i} \right) -
\min \left( d \left( \textbf{a}_i , \textbf{p}_{j_{ \min }} \right) , d
\left( \textbf{a}_{k_{ \min }} , \textbf{p}_{i} \right) \right)
\right)\]</span></p>
<p>损失函数对应的代码为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">triplet_loss</span>(<span class="params">x, label, margin=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="comment"># x is D x N</span></span><br><span class="line">    dim = x.size(<span class="number">0</span>) <span class="comment"># D</span></span><br><span class="line">    nq = torch.<span class="built_in">sum</span>(label.data==-<span class="number">1</span>).item() <span class="comment"># number of tuples</span></span><br><span class="line">    S = x.size(<span class="number">1</span>) // nq <span class="comment"># number of images per tuple including query: 1+1+n</span></span><br><span class="line"></span><br><span class="line">    xa = x[:, label.data==-<span class="number">1</span>].permute(<span class="number">1</span>,<span class="number">0</span>).repeat(<span class="number">1</span>,S-<span class="number">2</span>).view((S-<span class="number">2</span>)*nq,dim).permute(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">    xp = x[:, label.data==<span class="number">1</span>].permute(<span class="number">1</span>,<span class="number">0</span>).repeat(<span class="number">1</span>,S-<span class="number">2</span>).view((S-<span class="number">2</span>)*nq,dim).permute(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">    xn = x[:, label.data==<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    dist_pos = torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(xa - xp, <span class="number">2</span>), dim=<span class="number">0</span>)</span><br><span class="line">    dist_neg = torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(xa - xn, <span class="number">2</span>), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.<span class="built_in">sum</span>(torch.clamp(dist_pos - dist_neg + margin, <span class="built_in">min</span>=<span class="number">0</span>)) / nq</span><br></pre></td></tr></table></figure>
<h3
id="sosnet-sosnet-second-order-similarity-regularization-for-local-descriptor-learning">SOSNet
| <a href="https://arxiv.org/abs/1904.05019">SOSNet: Second Order
Similarity Regularization for Local Descriptor Learning</a></h3>
<p>HardNet的loss是由距离度量直接组成的，其可以被认为是基于一阶相似距离的loss。SOSNet在此之上又增加了基于二阶相似距离的loss。</p>
<p>所谓二阶距离，这里指在四元组 <span
class="math inline">\((\textbf{a}_i, \textbf{p}_{i}, \textbf{p}_{j_{
\min }}, \textbf{a}_{k_{ \min }})\)</span> 中两个 anchor-negative
距离的距离， 即 <span class="math inline">\(d \left( d \left(
\textbf{a}_i , \textbf{p}_{j_{ \min }} \right) , d \left(
\textbf{a}_{k_{ \min }} , \textbf{p}_{i} \right)
\right)\)</span>。通过最小化二阶距离，可使得local
descriptor更加聚积，如下图所示。</p>
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/second_order_dist.jpg" class="" title="Second_Order_Distance">
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/sosnet.jpg" class="" title="SOSNet_output">
<p>二阶距离损失函数对应的代码为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sos_loss</span>(<span class="params">x, label</span>):</span><br><span class="line">    <span class="comment"># x is D x N</span></span><br><span class="line">    dim = x.size(<span class="number">0</span>) <span class="comment"># D</span></span><br><span class="line">    nq = torch.<span class="built_in">sum</span>(label.data==-<span class="number">1</span>).item() <span class="comment"># number of tuples</span></span><br><span class="line">    S = x.size(<span class="number">1</span>) // nq <span class="comment"># number of images per tuple including query: 1+1+n</span></span><br><span class="line"></span><br><span class="line">    xa = x[:, label.data==-<span class="number">1</span>].permute(<span class="number">1</span>,<span class="number">0</span>).repeat(<span class="number">1</span>,S-<span class="number">2</span>).view((S-<span class="number">2</span>)*nq,dim).permute(<span class="number">1</span>,<span class="number">0</span>) <span class="comment"># D * (B * num_neg)</span></span><br><span class="line">    xp = x[:, label.data==<span class="number">1</span>].permute(<span class="number">1</span>,<span class="number">0</span>).repeat(<span class="number">1</span>,S-<span class="number">2</span>).view((S-<span class="number">2</span>)*nq,dim).permute(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">    xn = x[:, label.data==<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    dist_an = torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(xa - xn, <span class="number">2</span>), dim=<span class="number">0</span>)</span><br><span class="line">    dist_pn = torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(xp - xn, <span class="number">2</span>), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(dist_an - dist_pn, <span class="number">2</span>)) ** <span class="number">0.5</span> / nq</span><br></pre></td></tr></table></figure>
<h3
id="log-polar-transformation-beyond-cartesian-representations-for-local-descriptors">Log
Polar Transformation | <a href="https://arxiv.org/abs/1908.05547">Beyond
Cartesian Representations for Local Descriptors</a></h3>
<p>另一篇对局部特征很有帮助的工作是Log Polar
Transformation。其核心是通过在图像预处理中引入Log Polar
Transformation，将图像从欧式坐标系转换为<a
href="https://en.wikipedia.org/wiki/Log-polar_coordinates">对数极坐标系</a>表示。由于不同的旋转和尺度变化在对数极坐标系下对图像不会有太大影响，因此Log
Polar Transformation会使得模型对旋转和尺度变化的鲁棒性较好。</p>
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/log_polar_transformation.jpg" class="" title="Rotation and Scaling transformations to a Euclidean image can be read as horizontal and vertical shift respectively, after a log-polar transformation. The log-polar transformation translates rotation and scale in Euclidean images into vertical and horizontal translations (respectively) in the log-polar model.">
<p>如上图所示，在欧式图像上的旋转和尺度变化对应到对数极坐标系下是竖直和水平方向上的平移变化。而卷积操作的滑动窗口计算方式使得其对平移变化非常鲁棒。需要注意的是，由于一般Patch-based卷积神经网络都非常浅，导致其无法很好的消除由旋转的尺度变化所导致的偏差。甚至为了消除这种偏差，在工程上常常使用重力的方向来旋转输入CNN的Patch。因此，Log
Polar
Transformation通过增强模型对旋转和尺度变化的鲁棒性，进而提升了模型的鲁棒性和准确度。</p>
<p>更多的旋转和尺度变化在对欧式坐标系和对数极坐标系的表现如下图所示。</p>
<img data-src="/zh/2022/02/27/zh/patch_based_local_descriptor/log_poloar_samples.jpg" class="" title="Example of rotation and scale transformations for a single MNIST image.">
<p>Log Polar Transformation在图像预处理时可以实现为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">to_log_polar</span>(<span class="params">img, dsize, max_radius</span>):</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(img, Image.Image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dsize = img.size</span></span><br><span class="line">    center = [s // <span class="number">2</span> <span class="keyword">for</span> s <span class="keyword">in</span> img.size]</span><br><span class="line">    flags = cv2.WARP_POLAR_LOG</span><br><span class="line">    out = cv2.warpPolar(</span><br><span class="line">        np.asarray(img), dsize=dsize, center=center, maxRadius=max_radius, flags=flags</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> Image.fromarray(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">from_log_polar</span>(<span class="params">polar_img, dsize, max_radius</span>):</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(polar_img, Image.Image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dsize = polar_img.size</span></span><br><span class="line">    center = [s // <span class="number">2</span> <span class="keyword">for</span> s <span class="keyword">in</span> polar_img.size]</span><br><span class="line">    flags = cv2.WARP_POLAR_LOG | cv2.WARP_INVERSE_MAP</span><br><span class="line">    out = cv2.warpPolar(</span><br><span class="line">        np.asarray(polar_img),</span><br><span class="line">        dsize=dsize,</span><br><span class="line">        center=center,</span><br><span class="line">        maxRadius=max_radius,</span><br><span class="line">        flags=flags,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> Image.fromarray(out)</span><br></pre></td></tr></table></figure>
<p>需要注意的是由于pytorch GridSample 的计算方式不同，用opencv实现的log
polar
transform会与论文原始PTN网络输出不一致，对于原始PTN网络实现可以参考<a
href="https://github.com/cvlab-epfl/log-polar-descriptors/blob/master/modules/ptn/pytorch/models.py">论文代码</a>。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a
href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Tian_L2-Net_Deep_Learning_CVPR_2017_paper.pdf">L2-Net:
Deep Learning of Discriminative Patch Descriptor in Euclidean
Space</a></li>
<li><a href="https://arxiv.org/abs/1705.10872">Working hard to know your
neighbor's margins: Local descriptor learning loss</a></li>
<li><a href="https://arxiv.org/abs/1904.05019">SOSNet: Second Order
Similarity Regularization for Local Descriptor Learning</a></li>
<li><a href="https://arxiv.org/abs/1908.05547">Beyond Cartesian
Representations for Local Descriptors</a></li>
<li><a href="https://arxiv.org/abs/1911.01141">Human eye inspired
log-polar pre-processing for neural networks</a></li>
</ul>
]]></content>
      <categories>
        <category>computer vision</category>
        <category>local descriptor</category>
      </categories>
      <tags>
        <tag>local descriptor</tag>
      </tags>
  </entry>
</search>
