<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/zh/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/zh/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/zh/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/zh/images/logo.svg" color="#222">

<link rel="stylesheet" href="/zh/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"foreveryounggithub.github.io","root":"/zh/","images":"/zh/images","scheme":"Muse","darkmode":true,"version":"8.11.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/zh/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/zh/js/config.js"></script>

    <meta name="description" content="TensorRT(TRT)是NVIDIA推出的一个高性能的深度学习推理框架，可以让深度学习模型在NVIDIA GPU上实现低延迟，高吞吐量的部署。主流框架的模型可以通过转换为TensorRT在NVIDIA GPU进而达到极大地提速。然而，由于TensorRT并不支持常见的图片数据类型uint8，这使得往往需要在cpu上进行图片数据预处理，转换为其所支持的float并传入到gpu模型输入。当图片较大">
<meta property="og:type" content="article">
<meta property="og:title" content="通过NPP加速TensorRT部署时图片数据预处理">
<meta property="og:url" content="https://foreveryounggithub.github.io/zh/2020/06/17/zh/trt_preproc_npp/index.html">
<meta property="og:site_name" content="ForeverYoung">
<meta property="og:description" content="TensorRT(TRT)是NVIDIA推出的一个高性能的深度学习推理框架，可以让深度学习模型在NVIDIA GPU上实现低延迟，高吞吐量的部署。主流框架的模型可以通过转换为TensorRT在NVIDIA GPU进而达到极大地提速。然而，由于TensorRT并不支持常见的图片数据类型uint8，这使得往往需要在cpu上进行图片数据预处理，转换为其所支持的float并传入到gpu模型输入。当图片较大">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-06-17T05:00:00.000Z">
<meta property="article:modified_time" content="2022-03-03T14:48:43.265Z">
<meta property="article:author" content="Yang">
<meta property="article:tag" content="cuda">
<meta property="article:tag" content="cpp">
<meta property="article:tag" content="tensorrt">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://foreveryounggithub.github.io/zh/2020/06/17/zh/trt_preproc_npp/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://foreveryounggithub.github.io/zh/2020/06/17/zh/trt_preproc_npp/","path":"2020/06/17/zh/trt_preproc_npp/","title":"通过NPP加速TensorRT部署时图片数据预处理"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>通过NPP加速TensorRT部署时图片数据预处理 | ForeverYoung</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-G3D5MFLVRD"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-G3D5MFLVRD","only_pageview":false}</script>
  <script src="/zh/js/third-party/analytics/google-analytics.js"></script>




<script type="text/javascript">
    // Wait for the page to load first
    var _prevOnload = window.onload;
    window.onload = function() {
        var switchLang = document.getElementsByClassName("menu-item menu-item-switch_lang")[0];
        switchLang.onclick = function() {
            var href = window.location.href;
            var indexOfZh = href.toLowerCase().indexOf('/zh/');
            if(indexOfZh !== -1) {
                href = href.replace('/zh/', '/');

                var indexOfEn = href.toLowerCase().indexOf('/zh/');
                if(indexOfEn !== -1) {
                    href = href.replace('/zh/', '/en/');
                }
                window.location.href = href;
            }
            else {
                href = href.replace(/(^http[s]?:\/\/[a-z0-9.]*[:?0-9]*\/)(.*)/i, '$1zh/$2');

                var indexOfEn = href.toLowerCase().indexOf('/en/');
                if(indexOfEn !== -1) {
                   href = href.replace('/en/', '/zh/');
                }
                window.location.href = href;
            }
            if(typeof(_prevOnload) === 'function') {
                _prevOnload();
            }
            return false;
        }
    }
</script>
  <noscript>
    <link rel="stylesheet" href="/zh/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/zh/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">ForeverYoung</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">driving into the distance</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/zh/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/zh/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/zh/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/zh/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-switch_lang"><a href="/zh/" rel="section"><i class="fa fa-language fa-fw"></i>EN</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83"><span class="nav-number">1.</span> <span class="nav-text">基本环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cpu%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">CPU图片数据预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gpu-npp%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">3.</span> <span class="nav-text">GPU-NPP图片数据预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">4.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/zh/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/zh/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/zh/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://foreveryounggithub.github.io/zh/2020/06/17/zh/trt_preproc_npp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zh/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ForeverYoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="通过NPP加速TensorRT部署时图片数据预处理 | ForeverYoung">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          通过NPP加速TensorRT部署时图片数据预处理
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-06-17 00:00:00" itemprop="dateCreated datePublished" datetime="2020-06-17T00:00:00-05:00">2020-06-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-03-03 09:48:43" itemprop="dateModified" datetime="2022-03-03T09:48:43-05:00">2022-03-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/zh/categories/model-inference/" itemprop="url" rel="index"><span itemprop="name">model inference</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>TensorRT(TRT)是NVIDIA推出的一个高性能的深度学习推理框架，可以让深度学习模型在NVIDIA
GPU上实现低延迟，高吞吐量的部署。主流框架的模型可以通过转换为TensorRT在NVIDIA
GPU进而达到极大地提速。然而，由于TensorRT并不支持常见的图片数据类型uint8，这使得往往需要在cpu上进行图片数据预处理，转换为其所支持的float并传入到gpu模型输入。当图片较大时，数据在cpu上的处理和传递时间较慢。本文将介绍如何通过cuda中的npp库来加速这一过程。</p>
<span id="more"></span>
<h2 id="基本环境">基本环境</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYS: Ubuntu 18.04</span><br><span class="line">GPU: T4</span><br><span class="line">GCC: 7.5</span><br><span class="line">CMake: 3.16.6</span><br><span class="line">CUDA: 10.2</span><br><span class="line">CUDNN: 7.6.5</span><br><span class="line">TensorRT: 7.0</span><br><span class="line">OpenCV: 4.3.0/3.4.10</span><br></pre></td></tr></table></figure>
<p>模型是由ssds.pytorch训练的Yolov3目标检测器，已转换为TRT模型。其输入大小为1x3x736x1280，特征提取器为ResNet18，计算精度为int8。</p>
<p>需要注意，当将模型转换为TRT模型时，TRT会根据gpu框架和性能来来选择不同的核函数及其参数，进而最大程度优化推理速度。因此TRT在执行时，必须使用统一gpu框架所生成的TRT模型，否则将无法推断。并且即使是统一框架不同型号的gpu所生成的TRT模型，其推理速度也会有些许削弱。比如虽然2080ti和t4同属7.5计算框架，在T4上推断，由2080ti所生成的TRT模型要比由T4生成的模型推断速度慢3~10%。</p>
<h2 id="cpu图片数据预处理">CPU图片数据预处理</h2>
<p>在一些深度学习框架中，在其推断时可以指定推断时所接受的数据类型，并将数据预处理的步骤在计算图中定义。如在tensorflow将权重转化为推断模型(frozen
graph)时，可以通过<code>tf.placeholder(dtype=tf.uint8, shape=input_shape, name='image_tensor')</code>来指定推理时模型接受的数据类型。这种改变在推理时模型的操作在TensorRT上似乎不那么行得通。虽然TensorRT支持多种数据类型，并且输入输出接口的数据类型可由转换的onnx或uff文件决定，但当输入输出的数据类型改为除float32以外的其他类型时，常常无法成功转换为TRT推理模型。</p>
<p>TensorRT中这种输入输出类型的限制，对于计算机视觉的模型显得更加不友好。计算机视觉常处理的图像或视频在计算机中常存储为0～255的uint8数据，这种类型本身就不被TensorRT所支持，须将图片先转为float数据再输入到TensorRT。而在一些任务中，其输入模型的图片或视频片段分辨率较大，如4k或8k，uint8和float从cpu内存传输到gpu显存的速度差别就比较大。这些原因导致了在计算机视觉模型部署时，图片数据预处理和传输有时候成为了模型部署的瓶颈。</p>
<p>大多数github上的TRT项目在进行推断中的图片数据预处理常采用TensorRT<a
target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/blob/572d54f91791448c015e74a4f1d6923b77b79795/samples/opensource/sampleSSD/sampleSSD.cpp#L276-L309">官方示例</a>中给出了一种在CPU图片数据预处理。笔者个人喜欢用OpenCV自带函数进行操作，这两种图片数据预处理的示例代码如下。</p>
<details>
<summary>
代码：CPU图片数据预处理
</summary>
<p>TensorRT官方示例图片数据预处理代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">SampleUffSSD::processInput</span><span class="params">(<span class="type">const</span> samplesCommon::BufferManager&amp; buffers)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> inputC = mInputDims.d[<span class="number">0</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> inputH = mInputDims.d[<span class="number">1</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> inputW = mInputDims.d[<span class="number">2</span>];</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> batchSize = mParams.batchSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Available images</span></span><br><span class="line">    std::vector&lt;std::string&gt; imageList = &#123;<span class="string">&quot;dog.ppm&quot;</span>, <span class="string">&quot;bus.ppm&quot;</span>&#125;;</span><br><span class="line">    mPPMs.<span class="built_in">resize</span>(batchSize);</span><br><span class="line">    <span class="built_in">assert</span>(mPPMs.<span class="built_in">size</span>() &lt;= imageList.<span class="built_in">size</span>());</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; batchSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">readPPMFile</span>(<span class="built_in">locateFile</span>(imageList[i], mParams.dataDirs), mPPMs[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span>* hostDataBuffer = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>*&gt;(buffers.<span class="built_in">getHostBuffer</span>(mParams.inputTensorNames[<span class="number">0</span>]));</span><br><span class="line">    <span class="comment">// Host memory for input buffer</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>, volImg = inputC * inputH * inputW; i &lt; mParams.batchSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; inputC; ++c)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// The color image to input should be in BGR order</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">unsigned</span> j = <span class="number">0</span>, volChl = inputH * inputW; j &lt; volChl; ++j)</span><br><span class="line">            &#123;</span><br><span class="line">                hostDataBuffer[i * volImg + c * volChl + j]</span><br><span class="line">                    = (<span class="number">2.0</span> / <span class="number">255.0</span>) * <span class="built_in">float</span>(mPPMs[i].buffer[j * inputC + c]) - <span class="number">1.0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenCV图片数据预处理代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">imageToTensor</span><span class="params">(<span class="type">const</span> std::vector&lt;cv::Mat&gt; &amp; images, <span class="type">float</span> * tensor, <span class="type">const</span> <span class="type">int</span> batch_size, <span class="type">const</span> <span class="type">float</span> alpha, <span class="type">const</span> <span class="type">float</span> beta)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> height = images[<span class="number">0</span>].rows;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> width = images[<span class="number">0</span>].cols;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> channels = images[<span class="number">0</span>].<span class="built_in">channels</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stridesCv[<span class="number">3</span>] = &#123; width * channels, channels, <span class="number">1</span> &#125;;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> strides[<span class="number">4</span>] = &#123; height * width * channels, height * width, width, <span class="number">1</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> omp parallel for num_threads(c_numOmpThread) schedule(static, 1)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> b = <span class="number">0</span>; b &lt; batch_size; b++)</span><br><span class="line">    &#123;</span><br><span class="line">        cv::Mat image_f;</span><br><span class="line">        images[b].<span class="built_in">convertTo</span>(image_f, CV_32F, alpha, beta);</span><br><span class="line">        std::vector&lt;cv::Mat&gt; split_channels = &#123;</span><br><span class="line">                cv::<span class="built_in">Mat</span>(images[b].<span class="built_in">size</span>(),CV_32FC1,tensor + b * strides[<span class="number">0</span>]),</span><br><span class="line">                cv::<span class="built_in">Mat</span>(images[b].<span class="built_in">size</span>(),CV_32FC1,tensor + b * strides[<span class="number">0</span>] + strides[<span class="number">1</span>]),</span><br><span class="line">                cv::<span class="built_in">Mat</span>(images[b].<span class="built_in">size</span>(),CV_32FC1,tensor + b * strides[<span class="number">0</span>] + <span class="number">2</span>*strides[<span class="number">1</span>]),</span><br><span class="line">        &#125;;</span><br><span class="line">        cv::<span class="built_in">split</span>(image_f, split_channels);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batch_size * height * width * channels;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenCV图片数据预处理运算速度(ms)</p>
<table>
<colgroup>
<col style="width: 38%" />
<col style="width: 17%" />
<col style="width: 13%" />
<col style="width: 15%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">GPU(Precision)</th>
<th style="text-align: center;">Image2Float</th>
<th style="text-align: center;">Copy2GPU</th>
<th style="text-align: center;">Inference</th>
<th style="text-align: center;">GPU2CPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">t4(int8)</td>
<td style="text-align: center;">2.53026</td>
<td style="text-align: center;">0.935451</td>
<td style="text-align: center;">2.56143</td>
<td style="text-align: center;">0.0210528</td>
</tr>
</tbody>
</table>
</details>
<p>如上例代码所示，在CPU图片数据预处理中，首先将数据转化为float类型并做归一化，然后将数据排列从NHWC转化为NCHW，最后将float型nchw图片数据传递给到TRT模型预留的gpu显存。可以看到，对于该模型图像预处理和传输的速度反而大于模型推断速度。这种cpu图片预处理方式无法高效使用gpu的性能，使得整个模型部署效率较低。</p>
<h2 id="gpu-npp图片数据预处理">GPU-NPP图片数据预处理</h2>
<p>上面提到，cpu图片数据预处理效率较低由两方面原因导致：其一，cpu将图像从uint8转化为float32的效率较低；其二，相较于uint8，float32从cpu传输到gpu数据量大四倍，传输效率较慢。所以比较朴素的提速想法就是将uint8数据传输到gpu，并由gpu完成从uint8转化为float32的转化。NPP就可以方便快速的实现如上过程。</p>
<p>NPP是nvidia推出的用于gpu加速2D图像和信号处理的cuda库，其本身就内嵌于cuda库中。其分为多个部分，可以在gpu上高效的进行数据类型转换，颜色变化，几何变化等功能。本例中采用其中的NPPC，NPPIDEI和NPPIAL部分来进行图片数据预处理中的uint8到float32的数据类型转化，NHWC到NCHW的通道变化，以及归一化操作。其具体代码如下。</p>
<details>
<summary>
代码：GPU-NPP图片数据预处理
</summary>
<p>NPP图片数据预处理代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">imageToTensorGPUFloat</span><span class="params">(<span class="type">const</span> std::vector&lt;cv::Mat&gt; &amp; images, <span class="type">void</span> * gpu_images, <span class="type">void</span> * tensor, <span class="type">const</span> <span class="type">int</span> batch_size, <span class="type">const</span> <span class="type">float</span> alpha)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> height = images[<span class="number">0</span>].rows;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> width  = images[<span class="number">0</span>].cols;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> channels = images[<span class="number">0</span>].<span class="built_in">channels</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stride = height * width * channels;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stride_s = width * channels;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> dstOrder[<span class="number">3</span>] = &#123;<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>&#125;;</span><br><span class="line">    Npp32f scale[<span class="number">3</span>] = &#123;alpha, alpha, alpha&#125;;</span><br><span class="line">    NppiSize dstSize = &#123;width, height&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> omp parallel for num_threads(c_numOmpThread) schedule(static, 1)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> b = <span class="number">0</span>; b &lt; batch_size; b++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cudaMemcpy</span>((Npp8u*)gpu_images + b * stride, images[b].data, stride, cudaMemcpyHostToDevice);</span><br><span class="line">        <span class="built_in">nppiSwapChannels_8u_C3IR</span>((Npp8u*)gpu_images + b * stride, stride_s, dstSize, dstOrder);</span><br><span class="line">        <span class="built_in">nppiConvert_8u32f_C3R</span>((Npp8u*)gpu_images + b * stride, stride_s, (Npp32f*)tensor, stride_s*<span class="built_in">sizeof</span>(<span class="type">float</span>), dstSize);</span><br><span class="line">        <span class="built_in">nppiMulC_32f_C3IR</span>(scale, (Npp32f*)tensor, stride_s*<span class="built_in">sizeof</span>(<span class="type">float</span>), dstSize);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batch_size * stride;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>NPP图片数据预处理代码（无通道变化和归一化） <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">imageToTensorGPUFloat</span><span class="params">(<span class="type">const</span> std::vector&lt;cv::Mat&gt; &amp; images, <span class="type">void</span> * gpu_images, <span class="type">void</span> * tensor, <span class="type">const</span> <span class="type">int</span> batch_size)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> height = images[<span class="number">0</span>].rows;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> width  = images[<span class="number">0</span>].cols;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> channels = images[<span class="number">0</span>].<span class="built_in">channels</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> stride = height * width * channels;</span><br><span class="line">    NppiSize dstSize = &#123;width, height&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">pragma</span> omp parallel for num_threads(c_numOmpThread) schedule(static, 1)</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> b = <span class="number">0</span>; b &lt; batch_size; b++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cudaMemcpy</span>((Npp8u*)gpu_images + b * stride, images[b].data, stride, cudaMemcpyHostToDevice);</span><br><span class="line">        <span class="built_in">nppiConvert_8u32f_C3R</span>((Npp8u*)gpu_images + b * stride, width * channels, (Npp32f*)tensor, width * channels*<span class="built_in">sizeof</span>(<span class="type">float</span>), dstSize);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batch_size * stride;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>NPP图片数据预处理（无通道变化和归一化）运算速度(ms)</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">GPU(Precision)</th>
<th style="text-align: center;">Image2GPU2Float</th>
<th style="text-align: center;">Inference</th>
<th style="text-align: center;">GPU2CPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">t4(int8)</td>
<td style="text-align: center;">0.532469</td>
<td style="text-align: center;">3.07869</td>
<td style="text-align: center;">0.0208867</td>
</tr>
</tbody>
</table>
</details>
<p>如上例代码所示，在GPU图片数据预处理中，首先将uint8数据传输到gpu显存中，然后将数据排列从NHWC转化为NCHW，最后转化为float类型并做归一化，归一化后的数据直接存储在TRT模型预留的gpu显存中。由于按位运算(elementwise)和通道转换(channel
permute)在TRT模型中执行效率较高，可将预处理中的归一化和通道转换移到模型内计算。可以看到，相较于cpu的图像预处理，gpu图像预处理的时间从3.5ms降到0.5ms，整个模型总运行时间从6ms降到3.5ms，每秒帧处理量（fps）从166帧提升到了285帧，整体达到了1.7倍的提速。</p>
<p>需要注意的是，由于TRT模型转化时间较长，本文示例只测试batch为1时的执行速度。如果在部署时遇到batch较大而导致gpu图片预处理速度较慢，由于cuda代码执行和传输特性，可考虑整批图像一起从cpu内存拷贝到gpu并进行uint8到float32的转化，进而提高大batch情况下的GPU图片数据预处理处理速度。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a
target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/infer/FoundationalTypes/DataType.html">tensorrt
document</a></li>
<li><a
target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus#compute">gpu计算框架</a></li>
<li><a
target="_blank" rel="noopener" href="https://github.com/ShuangXieIrene/ssds.pytorch">ssds.pytorch</a></li>
</ul>
<p>如果有TensorRT的项目，不妨来试试通过本文提到的GPU图片数据预处理的方法来提速模型推断流程的速度吧！</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/zh/tags/cuda/" rel="tag"># cuda</a>
              <a href="/zh/tags/cpp/" rel="tag"># cpp</a>
              <a href="/zh/tags/tensorrt/" rel="tag"># tensorrt</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/zh/2020/06/10/zh/numba_cuda/" rel="prev" title="Numba: 通过python快速学习cuda编程">
                  <i class="fa fa-chevron-left"></i> Numba: 通过python快速学习cuda编程
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/zh/2020/07/04/zh/numba_python/" rel="next" title="Numba: 简单装饰器加速python代码">
                  Numba: 简单装饰器加速python代码 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/zh/js/comments.js"></script><script src="/zh/js/utils.js"></script><script src="/zh/js/motion.js"></script><script src="/zh/js/schemes/muse.js"></script><script src="/zh/js/next-boot.js"></script><script src="/zh/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/zh/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.14.0/dist/mermaid.min.js","integrity":"sha256-7wT34TI0pEBeEFoi4z+vhuSddGh6vUTMWdqJ2SDe2jg="}}</script>
  <script src="/zh/js/third-party/tags/mermaid.js"></script>

  <script src="/zh/js/third-party/fancybox.js"></script>


  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/zh/js/third-party/math/mathjax.js"></script>



</body>
</html>
